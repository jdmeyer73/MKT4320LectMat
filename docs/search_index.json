[["index.html", "MKT 4320: Marketing Analytics Lecture Materials Introduction", " MKT 4320: Marketing Analytics Lecture Materials Jeffrey Meyer 2022-01-16 Introduction This web-book will serve as your copies of the lecture slides. Because the software used in this class is R and RStudio, traditional lecture slides for students are not useful, because I want to provide the code that generated the output seen on the slides. Each topic covered is a chapter in this web-book and will begin with a motivation section, followed by the R packages and datasets used in that topic. The sections after that will provide an web version of the material on the lecture slides used in class. "],["examining-and-summarizing-data.html", "Chapter 1 Examining and Summarizing Data 1.1 Motivation 1.2 R Packages and Datasets for Topic 1 1.3 Describing Data 1.4 Suggested Readings 1.5 R Code", " Chapter 1 Examining and Summarizing Data 1.1 Motivation After data preparation, examining and summarizing the data provides the analyst with a feel for the data Distributions of variables Relationships between variables Missing observations Coding of variables 1.2 R Packages and Datasets for Topic 1 library(ggplot2) # Advanced graphing capabilities library(dplyr) # Easier programming library(tidyr) # Easier programming library(scales) # Control appearance of axes and legend labels library(questionr) # Easier frequency tables library(htmlTable) # Better HTML Tables library(mosaic) # Statistical functions library(sjPlot) # Easily create cross-tabs load(&quot;Topic01/airlinesat.rdata&quot;) Download airlinesat.rdata 1.3 Describing Data How we examine and summarize data depends on: Type of data Nominal Ordinal Continuous Number of variables Univariate Bivariate 1.3.1 Univariate - Graphs and Tables 1.3.1.1 Bar Chart Primarily for nominal/ordinal data Displays each categorys Frequency (usually) Centrality Dispersion Figure 1.1: Bar Chart R Code 1.3.1.2 Histogram Non-overlapping categories of equal width from continuous data Shows frequency in each category Used to examine distribution of variable Figure 1.2: Historgram 1 R Code Figure 1.3: Histogram 2 R Code 1.3.1.3 Box Plot Displays distribution of continuous data Conveys dispersion information Wider box = More dispersion Can help identify potential outliers How to interpret: Box in middle is the Interquartile Range Q3 (75th percentile) - Q1 (25th percentile) Line in middle is the median Upper/lower lines are upper/lower adjacent values Upper adjacent value is the largest observation that is smaller than Q3 + 1.5*IQR Lower adject value is the smallest observatoin that is larger than Q1 - 1.5*IQR Any observations above (below) the upper (lower) adjacent value are plotted separately, and could be outliers Figure 1.4: Box Plot R Code 1.3.1.4 Frequency Table Displays counts and percentages for categorical variables Similar to bar chart, but in table form Table 1.1: Frequency Table n % val% %cum val%cum Blue 677 63.6 63.6 63.6 63.6 Gold 143 13.4 13.4 77 77 Silver 245 23 23 100 100 Total 1065 100 100 100 100 R Code 1.3.2 Univariate - Statistics 1.3.2.1 Measures of Centrality Values of a typical or average score Mean is the sum of all observations divided by the number of observations Only appropriate for continuous data Median separates highest and lowers 50% of observations Cannot be used on categorical data Table 1.2: Measures of Centrality and Dispersion age s1 Min. : 19.00 Min. : 1.00 1st Qu.: 42.00 1st Qu.: 46.00 Median : 50.00 Median : 58.00 Mean : 50.42 Mean : 60.91 3rd Qu.: 58.00 3rd Qu.: 84.00 Max. :101.00 Max. :100.00 NAs :27 R Code 1.3.2.2 Measures of Dispersion Provide info about variability in the data Range is the highest minus the lowest observation Simple, but includes extreme values Not appropriate for categorical data Interquartile Range (IQR) is Q3 (75th percentile) - Q1 (25th percentile) Used in the Box Plot Not appropriate for categorical data Standard Deviation Given by Equation 1.1 below \\[\\begin{equation} s = \\sqrt{\\frac{\\sum_{i=1}^{n}{(x_i - \\bar{x})^2}}{n-1}} \\tag{1.1} \\end{equation}\\] Only appropriate with continuous data Table 1.3 Measures of Centrality and Dispersion For (A) Age and (B) Airline gets me there on time (Satisfaction) (A) min Q1 median Q3 max mean sd n missing 19.00 42.00 50.00 58.00 101.00 50.42 12.27 1065.00 0.00 (B) min Q1 median Q3 max mean sd n missing 1.00 46.00 58.00 84.00 100.00 60.91 26.02 1038.00 27.00 R Code 1.3.3 Bivariate - Graphs and Tables 1.3.3.1 Scatterplots Graphically shows how two continuous variables are related If dots appear in to follow a line, variables are likely related (see Figure 1.5) If dots appear random, variables are likely not related (see Figure 1.6) Not appropriate for categorical data (see Figure 1.7) Figure 1.5: Scatterplot 1 with Fitted Line R Code Figure 1.6: Scatterplot 2 without Fitted Line R Code Figure 1.7: Scatterplot of Categorical Data R Code 1.3.3.2 Crosstabs Show if and how two categorical variables are related Common to put DV in rows and IV in columns Can ask for \\(\\chi^2\\) to test if for significant association Can also view it visually with a stacked bar chart (see Figure 1.8) Percentages represent column percentages Can also view it visually with separate bars for each category (see Figure 1.9) Bar height is percent of total Table 1.4: Crosstab flight_purpose flight_type Total Domestic International Business 33059.1 % 19538.5 % 52549.3 % Leisure 22840.9 % 31261.5 % 54050.7 % Total 558100 % 507100 % 1065100 % 2=44.619 · df=1 · =0.207 · p=0.000 R Code Figure 1.8: Stacked Bar Chart R Code Figure 1.9: Side-by-Side Bar Chart R Code 1.3.3.3 Box Plot Displays distribution of continuous data across classes of a categorical variable Figure 1.10: Box Plot by Category R Code 1.3.3.4 Bar Chart Displays mean (or some other value) of continuous data across classes of a categorical variable Figure 1.11: Bar Chart by Category R Code 1.3.4 Statistics 1.3.4.1 Correlation Provides a measure of linear association between two continuous variables Given by Equation 1.2 below \\[\\begin{equation} r = \\frac{\\sum_{i=1}^{n}{(x_i - \\bar{x})(y_i-\\bar{y})}}{(n-1)s_xs_y} \\tag{1.2} \\end{equation}\\] \\(-1 \\le r \\le 1\\) Table 1.5: Correlation Matrix age nflights e7 s11 age nflights -0.116*** e7 -0.034 -0.063* s11 0.170*** -0.106*** 0.240*** Computed correlation used pearson-method with pairwise-deletion. R Code 1.4 Suggested Readings R for Marketing Research and Analytics. 2nd Edition (2019). Chapman, Chris; McDonnel Feit, Elea BGSU Library Link:http://maurice.bgsu.edu/record=b4966554~S9 eBook through BGSU Library:https://link-springer-com.ezproxy.bgsu.edu/book/10.1007%2F978-3-030-14316-9 Chapter 3: Describing Data Chapter 4: Relationships Between Continuous Variables Chapter 5: Tables and Visualization OpenIntro Statistics. 4th Edition (2019). Diez, David; Cetinkaya-Rundel, Mine; Barr, Christopher D. Available at OpenIntro.org:https://www.openintro.org/book/os/ Summarizing Data Multivariate Data Analysis. Hair, Joseph F.; Black, William C.; Babin, Barry J.; Anderson, Rolph E. 7th Edition: Search for multivariate data analysis 7th edition hair Graphical Examination of the Data (pp. 34-40) 5th Edition: Course reserves Graphical Examination of the Data (pp. 40-46) 1.5 R Code 1.5.1 Table1.1 See Table 1.1 # Create frequency table using questionr::freq and pass result # htmlTable freq(airlinesat$status, cum=TRUE, total=TRUE) %&gt;% htmlTable() 1.5.2 Table1.2 See Table 1.2 airlinesat %&gt;% # Dataset # Select variables; Use &#39;dplyr::&#39; before &#39;select&#39; to avoid conflicts dplyr::select(age, s1) %&gt;% # Request summary statistics summary() %&gt;% # Create htmlTable htmlTable() 1.5.3 Table1.3 See Table 1.3 # Request htmlTable for summary statistics with rounding two 2 digits # for &#39;age&#39; htmlTable(txtRound(favstats(airlinesat$age),2), caption=&quot;Age&quot;) # Request htmlTable for summary statistics with rounding two 2 digits # for &#39;s1&#39; htmlTable(txtRound(favstats(airlinesat$s1),2), caption=&quot;Airline Gets me there on time (Satisfaction)&quot;) 1.5.4 Table1.4 See Table 1.4 # Use package sjPlot to easily create cross-tab # Note: sjPlot::tab_xtab not available in virtual environment tab_xtab(var.row=airlinesat$flight_purpose, # Set row variable var.col=airlinesat$flight_type, # Set column variable show.col.prc=TRUE) # Request column percentages 1.5.5 Table1.5 See Table 1.5 # Create dataframe of variables to include corrvars &lt;- airlinesat %&gt;% select(age, nflights, e7, s11) # Use package sjPlot to easily create correlation matrix # Note: sjPlot not available in virtual environment tab_corr(corrvars, na.deletion = &quot;pairwise&quot;, # Delete obs if either variable is missing corr.method = &quot;pearson&quot;, # Choose Pearson correlation coefficient show.p = TRUE, # Show asterisks for significant correlations digits = 3, # Show three decimal points triangle = &quot;lower&quot;, # Show only lower triangle fade.ns=FALSE) # Do not fade insignficant correlations # Note: For vitual environment, use package Hmisc to produce separate # tables for correlation coefficients and p-values htmlTable(txtRound(rcorr(as.matrix(corrvars))[[&quot;r&quot;]],3)) htmlTable(txtRound(rcorr(as.matrix(corrvars))[[&quot;P&quot;]],3)) 1.5.6 Figure 1.1 See Figure 1.1 airlinesat %&gt;% # Dataset # Groups dataset by variable &#39;status&#39; group_by(status) %&gt;% # Creates new variable &#39;n&#39; equal to number of obs for each status summarize(n=n()) %&gt;% # Creates new variable &#39;prop&#39; equal to proportion of same for each status mutate(prop=n/sum(n)) %&gt;% # Begins plot with &#39;status&#39; on x axis and &#39;prop&#39; on y axis ggplot(aes(x=status, y=prop)) + # Requests bar chart as the geom function, using actual value # of variable &#39;prop&#39; as the statistic to plot geom_bar(stat=&quot;identity&quot;) + # Adds data labels to the end of the bars geom_text(aes(label=sprintf(&quot;%1.1f%%&quot;, prop*100)), vjust=1.5, color=&quot;white&quot;) + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Status&quot;,y=&quot;Proportion&quot;) 1.5.7 Figure 1.2 See Figure 1.2 airlinesat %&gt;% # Dataset # Begins plot with &#39;age&#39; as variable to plot on x axis ggplot(aes(x=age)) + # Requests histogram as the geom function, with binwidth of 2, # y axis to represent density, and outline/color of bars geom_histogram(binwidth=2, aes(y=..density..), color=&quot;black&quot;, fill=&quot;tan&quot;) + # Creates normal curve overlay stat_function(fun=function(x) dnorm(x, mean=mean(airlinesat$age),sd=sd(airlinesat$age))) + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Age&quot;, y=&quot;Density&quot;) 1.5.8 Figure 1.3 See Figure 1.3 airlinesat %&gt;% # Dataset # Drops ros with missing values for variable &#39;s1&#39; drop_na(s1) %&gt;% # Begins plot with &#39;s1&#39; as variable to plot on x axis ggplot(aes(x=s1)) + # Requests histogram as the geom function, with binwidth of 2, # y axis to represent density, and outline/color of bars geom_histogram(binwidth=2, aes(y=..density..), color=&quot;black&quot;, fill=&quot;tan&quot;) + # Creates normal curve overlay stat_function(fun=function(x) dnorm(x, mean=mean(airlinesat$s1, na.rm=TRUE), sd=sd(airlinesat$s1, na.rm=TRUE))) + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Airline gets me there on time (Satisfaction)&quot;, y=&quot;Density&quot;) 1.5.9 Figure 1.4 See Figure 1.4 airlinesat %&gt;% # Dataset # Begins plot with no grouping variable and age as continuous variable ggplot(aes(x=&quot;&quot;, y=age)) + # Request boxplot as the geom function geom_boxplot() + # Adds the whiskers to the boxplot stat_boxplot(geom=&#39;errorbar&#39;) + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;&quot;, y=&quot;Age&quot;) 1.5.10 Figure 1.5 See Figure 1.5 airlinesat %&gt;% # Passes dataset to ggplot # Begins plot with x (s18) and y (s17) variables ggplot(aes(x=s18, y=s17)) + # Requests scatter plot geom_point() + # Requests linear regression fitted line without confidence interval geom_smooth(method=&quot;lm&quot;, se=FALSE) + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Employees are service-oriented (s18)&quot;, y=&quot;Employees are friendly (s17)&quot;) 1.5.11 Figure 1.6 See Figure 1.6 airlinesat %&gt;% # Passes dataset to ggplot # Begins plot with x (age) and y (s11) variables ggplot(aes(x=age, y=s11)) + # Requests scatter plot geom_point() + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Age&quot;, y=&quot;Aircraft interior is well maintained (s11)&quot;) 1.5.12 Figure 1.7 See Figure 1.7 airlinesat %&gt;% # Passes dataset to ggplot # Begins plot with x (age) and y (s11) variables ggplot(aes(x=flight_type, y=flight_purpose)) + # Requests scatter plot geom_point() + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Flight Type&quot;, y=&quot;Flight Purpose&quot;) 1.5.13 Figure 1.8 See Figure 1.8 airlinesat %&gt;% # Dataset # Groups dataset by crosstab variables group_by(flight_type, flight_purpose) %&gt;% # Creates new variable &#39;n&#39; for count of observations in each cell summarise(n=n()) %&gt;% # Creates column percentages mutate(prop=n/sum(n)) %&gt;% # Begins plot with &#39;flight_type&#39; on x, &#39;prop&#39; on y, and color of the # fill in the bars based on&#39;flight_purpose&#39; ggplot(aes(x=flight_type, y=prop, fill=flight_purpose)) + # Requests bar chart as the geom function, positioning the # location of the bars based on the fill variable geom_bar(position=&quot;fill&quot;, stat=&quot;identity&quot;) + # Labels y-axis using percentages scale_y_continuous(labels=scales::label_percent()) + # Adds data labels to middle of bars geom_text(aes(label=sprintf(&quot;%1.1f%%&quot;, prop*100)), position=position_stack(vjust=0.5), color=&quot;white&quot;) + # Changes test size to be larger theme(text=element_text(size=15)) + # Adds axis and legend labels labs(x=&quot;Flight Type&quot;, y=&quot;Percent&quot;, fill=&quot;Flight Purpose&quot;) 1.5.14 Figure 1.9 See Figure 1.9 airlinesat %&gt;% # Dataset # Groups dataset by crosstab variables group_by(flight_type, flight_purpose) %&gt;% # Creates new variable &#39;n&#39; for count of observations in each cell, but # drops grouping structure to get total percentages summarise(n=n(), .groups=&quot;drop&quot;) %&gt;% # Creates total percentages mutate(prop=n/sum(n)) %&gt;% # Begins plot with &#39;flight_type&#39; on x, &#39;prop&#39; on y, and color of the # fill in the bars based on&#39;flight_purpose&#39; ggplot(aes(x=flight_type, y=prop, fill=flight_purpose)) + # Requests bar chart as the geom function, positioning the # location of the bars to be side-by-side (dodge) geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + # Labels y-axis using percentages scale_y_continuous(labels=scales::label_percent()) + # Adds data labels to end of bars geom_text(aes(label=sprintf(&quot;%1.1f%%&quot;, prop*100)), vjust=1.5, position=position_dodge(width=.9), color=&quot;white&quot;) + # Changes test size to be larger theme(text=element_text(size=15)) + # Adds axis and legend labels labs(x=&quot;Flight Type&quot;, y=&quot;Percent&quot;, fill=&quot;Flight Purpose&quot;) 1.5.15 Figure 1.10 See Figure 1.10 airlinesat %&gt;% # Dataset # Begins plot with &#39;status&#39; as grouping variable and # &#39;age&#39; as continuous variable ggplot(aes(x=status, y=age)) + # Request boxplot as the geom function geom_boxplot() + # Adds the whiskers to the boxplot stat_boxplot(geom=&#39;errorbar&#39;) + # Changes text size to be larger theme(text=element_text(size=15)) + # Adds axis labels labs(x=&quot;Status&quot;, y=&quot;Age&quot;) 1.5.16 Figure 1.11 See Figure 1.11 airlinesat %&gt;% # Dataset # Groups dataset by &#39;crosstab variables&#39;status&#39; group_by(status) %&gt;% # Creates new variable &#39;mean&#39; for mean of &#39;age&#39; by &#39;status&#39; summarise(mean=mean(age)) %&gt;% # Begins plot with &#39;status&#39; on x, &#39;mean&#39; on y ggplot(aes(x=status, y=mean)) + # Requests bar chart as the geom function, plotting the actual # value (&#39;identity&#39;), and setting fill color to match status geom_bar(stat=&quot;identity&quot;, fill=c(&quot;midnightblue&quot;,&quot;gold&quot;,&quot;gray&quot;)) + # Sets number of breaks on y-axis scale_y_continuous(n.breaks=6) + # Adds data labels to outside end of bars geom_text(aes(label=sprintf(&quot;%.2f&quot;, mean)), vjust=-.5, position=position_dodge(width=.9), color=&quot;black&quot;) + # Changes test size to be larger theme(text=element_text(size=15)) + # Adds axis and legend labels labs(x=&quot;Status&quot;, y=&quot;Mean of Age&quot;) "],["linear-regression.html", "Chapter 2 Linear Regression 2.1 Motivation 2.2 R Packages and Datasets for Topic 2 2.3 Understanding Regression Analysis 2.4 Conducting Linear Regression 2.5 Linear Regression Example 2.6 Categorical IVs 2.7 Categorical IVs Example 2.8 Suggested Readings 2.9 R Code", " Chapter 2 Linear Regression 2.1 Motivation Regression allows marketers to: Understand relationships between a dependent variable and one or more independent variables Determine the relative strength of different independent variables Make predictions 2.2 R Packages and Datasets for Topic 2 library(ggplot2) # Advanced graphing capabilities library(tidyr) # Easier programming library(scales) # Control appearance of axes and legend labels library(htmlTable) # Better HTML Tables library(reshape2) # Easily convert wide data to long data library(GGally) # ggplot extension; for scatterplot matrix library(summarytools) # Summary statistics library(effects) # Help with linear predictions library(cowplot) # Arrange separate plots in a grid library(ggtext) # Annotate ggplots library(lubridate) # Easily work with dates library(jtools) # Concise regression results library(dplyr) # Easier programming library(broom) # Extract values from model load(&quot;Topic02/advtsales.rdata&quot;) load(&quot;Topic02/deptstoresales.rdata&quot;) Download advtsales.rdata Download deptstoresales.rdata 2.3 Understanding Regression Analysis Regression notation: \\(y = \\alpha + \\beta_kx_k+\\varepsilon\\) where \\(y\\) is the dependent variable (DV) \\(x_k\\) is the \\(k\\)th independent variable (IV) \\(\\alpha\\) is the constant or \\(y\\)-intercept \\(\\beta_k\\) is the regression coefficient for the \\(k\\)th IV \\(\\varepsilon\\) is the error term Objective Predict DV based on knowledge of the IV(s) Method OLS creates the best fitted line by minimizing the sum of the squared residuals OLS Minimizes Equation 2.1 below: \\[\\begin{equation} \\sum_{i=1}^{n}{(y_i - \\hat{y}_i)^2} \\tag{2.1} \\end{equation}\\] Note: The best fitted regression line is not always the line that best represents the data 2.4 Conducting Linear Regression 2.4.1 Check Data Requirements Continuous DV Must be measured on an interval or ratio scale For nominal scale, use logistic regression For ordinal scale, use ordinal regression 2.4.2 Model Specification Pick IVs based on Conceptual grounding Availability of data Including irrelevant IVs Reduces parsimony May mask effects of other IVs Makes testing significance less precise Excluding relevant IVs Seriously biases results Negatively affects interpretation 2.4.3 Model Estimation Estimately is typically done using OLS All statistical packages can conduct regression R lm(dv ~ iv1 + iv2 +  + ivk) Stata GUI Statistics &gt; Linear models and related &gt; Linear Regression Stata Command regress dv iv1 iv2  ivk SPSS GUI Analyze &gt; Regression &gt; Linear SPSS Syntax regression/dependent dv/enter iv1 iv2  ivk SAS proc reg; model dv = iv1 iv2  ivk; Minitab Stat &gt; Regression &gt; Regression 2.4.4 Model Interpetation Assessing Overall Model Fit How much variation in the DV is explained by the model Individual Independent Attributes Relationship between DV and each IV \\(H_0:\\beta_k=0\\) vs. \\(H_a:\\beta_k\\ne0\\) Interpret significant relationships Relative strength of IVs 2.4.5 Model Prediction Prediction is a key use of regression Estimate DV based on assumed values of IVs \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta_k}x_k\\) where \\(\\hat{y}\\) is predicted value of \\(y\\) for assumed values of \\(x_k\\) and Regression provided estimates of \\(\\alpha\\) and \\(\\beta_k\\) 2.5 Linear Regression Example 2.5.1 Overview Advertising and Sales data for 200 firms DV: Sales (in millions), \\(sales\\) IVs: TV Advertising (in 000s), \\(ad\\_tv\\) Radio Advertising (in 000s), \\(ad\\_radio\\) Paper Advertising (in 000s), \\(ad\\_paper\\) Model: \\(sales=\\alpha+\\beta_1ad\\_tv+\\beta_2ad\\_radio+\\beta_3ad\\_paper\\) Goal: Understand the relationship between various advertising types and sales 2.5.2 Summarize Data 2.5.2.1 Univariate Summary Statistics Table 2.1: Summary Statistics N.Valid Mean Std.Dev Min Max ad_paper 200.00 30.55 21.78 0.30 114.00 ad_radio 200.00 23.26 14.85 0.00 49.60 ad_tv 200.00 147.04 85.85 0.70 296.40 sales 200.00 14.02 5.22 1.60 27.00 R Code 2.5.2.2 Scatterplot and Correlation Matrix Figure 2.1: Scatterplot Matrix with Correlation R Code 2.5.2.3 Box Plots Figure 2.2: Box Plots R Code 2.5.3 Results 2.5.3.1 R Output 2.5.3.1.1 Regression Results (Concise) Estimated regression equation: \\(\\hat{sales}=2.939+.046ad\\_tv+.189ad\\_radio-.001ad\\_paper\\) Table 2.2: Regression Results (Concise) F(3,196) 570.2707 R² 0.8972 Adj. R² 0.8956 Est. S.E. t val. p (Intercept) 2.9389 0.3119 9.4223 0.0000 ad_tv 0.0458 0.0014 32.8086 0.0000 ad_radio 0.1885 0.0086 21.8935 0.0000 ad_paper -0.0010 0.0059 -0.1767 0.8599 Standard errors: OLS R Code 2.5.3.1.2 Standard Results Table 2.3: Regression Results (Standard) Call: lm(formula = sales ~ ad_tv + ad_radio + ad_paper, data = advtsales) Residuals: Min 1Q Median 3Q Max -8.8277 -0.8908 0.2418 1.1893 2.8292 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.938889 0.311908 9.422 &lt;2e-16 *** ad_tv 0.045765 0.001395 32.809 &lt;2e-16 *** ad_radio 0.188530 0.008611 21.893 &lt;2e-16 *** ad_paper -0.001037 0.005871 -0.177 0.86 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.686 on 196 degrees of freedom Multiple R-squared: 0.8972, Adjusted R-squared: 0.8956 F-statistic: 570.3 on 3 and 196 DF, p-value: &lt; 2.2e-16 R Code 2.5.3.2 Assessing Overall Model Fit How much variation in the DV is explained by the model Use \\(R^2\\) to assess Use \\(\\text{Adjusted }R^2\\) to compare models Conclusion: Based on the \\(R^2\\), about \\(90\\%\\) of the variance in \\(sales\\) is explained by the model 2.5.3.3 Individual Independent Variables Relationship between DV and each IV \\(H_0:\\beta_k=0\\) vs. \\(H_a:\\beta_k\\ne0\\) Interpret significant relationships With a \\(p\\text{-value}&lt;0.001\\), \\(ad\\_tv\\) has a significant effect on sales. A one unit increase in \\(ad_tv\\) is predicted to increases \\(sales\\) by \\(.0457\\) units. With a \\(p\\text{-value}&lt;0.001\\), \\(ad\\_radio\\) has a significant effect on sales. A one unit increase in \\(ad_radio\\) is predicted to increases \\(sales\\) by \\(.1885\\) units. With a \\(p\\text{-value}=.860\\), \\(ad\\_paper\\) has no significant effect on \\(sales\\). Relative strength of IVs For relative strength, use standardized \\(\\beta_k\\)s A standardized \\(\\beta_k\\) is the effect of a single standard deviation change in the IV on the DV Higher absolute values are more important Conclusion: \\(ad\\_tv\\) is the biggest driver of sales Table 2.4: Standardized Beta Coefficients ad_tv 0.7531 ad_radio 0.5365 ad_paper -0.0043 R Code Visualize each IV Sometimes it helps to visually examine the IVs for interprtation Plots show predicted DV at different levels of an IV, holding the other IVs constant at the mean value Figure 2.3: Margin Plots R Code 2.5.3.4 Model Prediction For simplicity, use only \\(ad\\_tv\\) and \\(ad\\_radio\\) Table 2.5: Coefficients Table for Reduced Model Est. S.E. t val. p (Intercept) 2.9211 0.2945 9.9192 0.0000 ad_tv 0.0458 0.0014 32.9087 0.0000 ad_radio 0.1880 0.0080 23.3824 0.0000 Standard errors: OLS R Code \\(\\hat{sales}=2.9211+.0458ad\\_tv+.1880ad\\_radio\\) Predict sales for $100K television advertising and $10K radio advertising \\(\\hat{sales}=2.9211+.0458(100)+.1880(10)=9.381= \\$9,381,000\\) Visually examine prediction at different levels of \\(ad\\_tv\\) and \\(ad\\_radio\\) Figure 2.4: Prediction Plots Figure 2.1: Prediction Plots R Code 2.6 Categorical IVs 2.6.1 Overview May want to represent a qualitative variable Gender of a buyer Success/Failure Region of the country Special situations But the IVs are supposed to be continuous Use dummy variables to indicate occurrence or nonoccurence of a particular attribute Coded as 1 (usually if true) or 0 (usually if false) Dummy variables can shift the intercept, the slope, or both Intercept Shifter Dummy is only its own term in the model \\(y=\\alpha+\\beta_1x+\\beta_2D\\) Slope Shifter Dummy is only an interaction with another IV \\(y=\\alpha+\\beta_1x+\\beta_2(x\\times D)\\) Intercept and Slope Shifter Dummy is own term and an interaction with IV \\(y=\\alpha+\\beta_1x+\\beta_2D+\\beta_3(x\\times D)\\) 2.6.2 Intercept Shifter \\(D=\\begin{cases}1\\text{ if true}\\\\0\\text{ if false}\\end{cases}\\) Model: \\(y=\\alpha+\\beta_1x+\\beta_2D\\) When \\(D=0\\): \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(0)\\\\&amp; = &amp; \\alpha + \\beta_1x\\end{array}\\) When \\(D=1\\): \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(1)\\\\&amp; = &amp; (\\alpha + \\beta_2)+\\beta_1x\\end{array}\\) 2.6.3 Slope Shifter \\(D=\\begin{cases}1\\text{ if true}\\\\0\\text{ if false}\\end{cases}\\) Model: \\(y=\\alpha+\\beta_1x+\\beta_2(x\\times D)\\) When \\(D=0\\): \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(x\\times 0)\\\\&amp; = &amp; \\alpha + \\beta_1x\\end{array}\\) When \\(D=1\\): \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(x\\times 1)\\\\&amp; = &amp; \\alpha + (\\beta_1+\\beta_2)x\\end{array}\\) Unusual to see only a slope shift 2.6.4 Intercept and Slope Shifter \\(D=\\begin{cases}1\\text{ if true}\\\\0\\text{ if false}\\end{cases}\\) Model: \\(y=\\alpha+\\beta_1x+\\beta_2D+\\beta_3(x\\times D)\\) When \\(D=0\\): \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(0)+\\beta_3(x\\times 0)\\\\&amp; = &amp; \\alpha + \\beta_1x\\end{array}\\) When \\(D=1\\): \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(1)+\\beta_3(x\\times 1)\\\\&amp; = &amp; (\\alpha + \\beta_2) + (\\beta_1 + \\beta_3)x\\end{array}\\) 2.6.5 Multiple Levels What if categorical IV has multiple levels (e.g., quarters)? Choose one level to be the base Create dummy variables for the other levels Levels must be mutually exclusive Dummy variables for four levels: Level 1, \\(L_1=\\begin{cases}1\\text{ if true}\\\\0\\text{ if false}\\end{cases}\\) Level 2, \\(L_2=\\begin{cases}1\\text{ if true}\\\\0\\text{ if false}\\end{cases}\\) Level 3, \\(L_3=\\begin{cases}1\\text{ if true}\\\\0\\text{ if false}\\end{cases}\\) Level 4, \\(L_4=\\text{base level; is true when }L_1=L_2=L_3=0\\) Model: \\(y=\\alpha + \\beta_1x + \\beta_2L_1+\\beta_3L_2+\\beta_4L_3\\) When Level 1: \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(1)+\\beta_3(0)+\\beta_4(0)\\\\&amp; = &amp; (\\alpha + \\beta_2) + \\beta_1x\\end{array}\\) When Level 2: \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(0)+\\beta_3(1)+\\beta_4(0)\\\\&amp; = &amp; (\\alpha + \\beta_3) + \\beta_1x\\end{array}\\) When Level 3: \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(0)+\\beta_3(0)+\\beta_4(1)\\\\&amp; = &amp; (\\alpha + \\beta_4) + \\beta_1x\\end{array}\\) When Level 4: \\(\\begin{array}{rcl}y &amp; = &amp; \\alpha+\\beta_1x+\\beta_2(0)+\\beta_3(0)+\\beta_4(0)\\\\&amp; = &amp; \\alpha + \\beta_1x\\end{array}\\) 2.7 Categorical IVs Example 2.7.1 Overview Sales data for 28 department store locations across 47 weeks and 69 departments DV: Department Sales, \\(sales\\) IVs: Overall Store Size, \\(size\\) Week, \\(week\\) where 1 = \\(week\\) ending 11/11/11 Predict sales by department Believe that the holiday season (or quarter 4) will be a driver of sales for some departments Generate dummy variable: \\(q4=\\begin{cases}1\\text{ if }week\\text{ in Quarter 4}\\\\0\\text{ otherwise}\\end{cases}\\) 2.7.2 Intercept Shift \\(sales = \\alpha + \\beta_1size+\\beta_2q4\\) Results: \\(sales\\) are significantly lower in Q4 (see Table 2.6 and Figure 2.5) Table 2.6: Regression Results (Intercept Shfit) for One Department F(2,1090) 126.1302 R² 0.1879 Adj. R² 0.1864 Est. S.E. t val. p (Intercept) 9993.3892 1890.0317 5.2874 0.0000 size 0.0546 0.0107 5.1210 0.0000 q4 -15153.3589 1012.8597 -14.9610 0.0000 Standard errors: OLS R Code Figure 2.5: Margin Plot for Intercept Shifter R Code 2.7.3 Slope Shift \\(sales = \\alpha + \\beta_1size+\\beta_2(size\\times q4)\\) Results: \\(sales\\) as a function of \\(size\\) are significantly lower in Q4 (see Table 2.7 and Figure 2.6) Table 2.7: Regression Results (Slope Shift) for One Department F(2,1090) 128.2440 R² 0.1905 Adj. R² 0.1890 Est. S.E. t val. p (Intercept) 6568.3795 1870.6049 3.5114 0.0005 size 0.0742 0.0107 6.9309 0.0000 size:q4 -0.0872 0.0058 -15.0986 0.0000 Standard errors: OLS R Code Figure 2.6: Margin Plot for Slope Shifter R Code 2.7.4 Intercept and Slope Shift \\(sales = \\alpha + \\beta_1size+\\beta_2q4+\\beta_3(size\\times q4)\\) Results: \\(sales\\) as a function of \\(size\\) are significantly lower in Q4 (see Table 2.8 and Figures 2.7 and 2.8) Table 2.8: Regression Results (Intercept &amp; Slope Shift) for One Department F(3,1089) 86.0379 R² 0.1916 Adj. R² 0.1894 Est. S.E. t val. p (Intercept) 7811.3235 2126.7243 3.6729 0.0003 size 0.0673 0.0121 5.5712 0.0000 q4 -5482.4234 4466.5447 -1.2274 0.2199 size:q4 -0.0567 0.0255 -2.2229 0.0264 Standard errors: OLS R Code Figure 2.7: Margin Plot for Intercept and Slope Shifter Showing \\(y\\)-intercept R Code Figure 2.8: Margin Plot for Intercept and Slope Shifter R Code 2.7.5 Intercept Shift with Multiple Levels \\(sales=\\alpha+\\beta_1size+\\beta_2q1+\\beta_3q2+\\beta_4q3\\) Q4 is set as the base level Results: \\(sales\\) are significantly lower in Q4 than in each of the other three quarters (see Table 2.9 and Figures 2.9 and 2.10) Table 2.9: Regression Results (Intercept Shift for Multiple Levels) for One Department F(4,1088) 307.2426 R² 0.5304 Adj. R² 0.5287 Est. S.E. t val. p (Intercept) -5354.0323 1539.7359 -3.4772 0.0005 size 0.0558 0.0081 6.8680 0.0000 quarter1 7268.7033 904.6239 8.0351 0.0000 quarter2 31313.5153 963.9526 32.4845 0.0000 quarter3 10436.9137 917.0085 11.3815 0.0000 Standard errors: OLS R Code Figure 2.9: Margin Plot for Multiple Levels Showing \\(y\\)-intercept R Code Figure 2.10: Margin Plot for Multiple Levels R Code 2.8 Suggested Readings R for Marketing Research and Analytics. 2nd Edition (2019). Chapman, Chris; McDonnel Feit, Elea BGSU Library Link:http://maurice.bgsu.edu/record=b4966554~S9 eBook through BGSU Library:https://link-springer-com.ezproxy.bgsu.edu/book/10.1007%2F978-3-030-14316-9 Chapter 7 OpenIntro Statistics. 4th Edition (2019). Diez, David; Cetinkaya-Rundel, Mine; Barr, Christopher D. Available at OpenIntro.org:https://www.openintro.org/book/os/ Chapter 8: Introduction to linear regression Chapter 9: Multiple and logistic regression Multivariate Data Analysis. Hair, Joseph F.; Black, William C.; Babin, Barry J.; Anderson, Rolph E. 7th Edition: Search for multivariate data analysis 7th edition hair Chapter 4: Multiple Regression Analysis 5th Edition: Course reserves Chapter 4: Multiple Regression Analysis 2.9 R Code 2.9.1 Table 2.1 See Table 2.1 # Creates dataframe with only needed variables; Use &#39;dplyr::&#39; before # &#39;select&#39; to avoid conflict with other packages lrreg1 &lt;- advtsales %&gt;% dplyr::select(-id) # Creates vector of stats to request in summarytools::descr stats &lt;- c(&quot;n.valid&quot;, &quot;mean&quot;, &quot;sd&quot;, &quot;min&quot;, &quot;max&quot;) # Use package summarytools to easily create summary statistics table # Note: summarytools::descr not available in virtual environment # Request htmlTable for summary statistics with rounding two 2 digits setHtmlTableTheme(&quot;Google&quot;) # Creates more compact table htmlTable(txtRound(descr(lrreg1, stats=stats, transpose=TRUE),2)) # Note: For virtual environment, use package mosaic::favstats to produce # separate summary statistics for each variable htmlTable(txtRound(favstats(lrreg1$ad_paper),2), caption=&quot;ad_paper&quot;) htmlTable(txtRound(favstats(lrreg1$ad_radio),2), caption=&quot;ad_radio&quot;) htmlTable(txtRound(favstats(lrreg1$ad_tv),2), caption=&quot;ad_tv&quot;) htmlTable(txtRound(favstats(lrreg1$sales),2), caption=&quot;sales&quot;) 2.9.2 Table 2.2 See Table 2.2 # Run linear model and save as &#39;results&#39; results &lt;- lm(sales ~ ad_tv + ad_radio + ad_paper, data = advtsales) # Create &#39;concise&#39; results using package &#39;jtools&#39; # NOTE: &#39;jtools&#39; not available in virtual environment; use standard results summ(results, digits=4, model.info=FALSE) 2.9.3 Table 2.3 See Table 2.3 # Run linear model and save as &#39;results&#39; results &lt;- lm(sales ~ ad_tv + ad_radio + ad_paper, data = advtsales) # Displays results summary(results) 2.9.4 Table 2.4 See Table 2.4 # Function to calculate standardized beta coefficients lm_beta &lt;- function (MOD) { b &lt;- summary(MOD)$coef[-1, 1] sx &lt;- sapply(MOD$model[-1], sd) sy &lt;- sapply(MOD$model[1], sd) beta &lt;- b * sx/sy return(beta) } # Create table setHtmlTableTheme(&quot;Google&quot;, css.table=&quot;width: 50%;&quot;) htmlTable(txtRound(as.matrix(lm_beta(results)), 4, scientific=FALSE)) 2.9.5 Table 2.5 See Table 2.5 # Run linear model and save as &#39;results&#39; resultssig &lt;- lm(sales ~ ad_tv + ad_radio, data = advtsales) # Create &#39;concise&#39; results using package &#39;jtools&#39; # NOTE: &#39;jtools&#39; not available in virtual environment; use standard results summ(resultssig, digits=4, model.info=FALSE, model.fit=FALSE) 2.9.6 Table 2.6 See Table 2.6 # Add Variables to &#39;dssales&#39; dataframe dssales &lt;- dssales %&gt;% # Add week ending date (&#39;weekdate&#39;) using package &#39;lubridate&#39; mutate(weekdate=ymd(&quot;2011-11-05&quot;) + (dssales$week-1)*7) %&gt;% # Add quarter based on &#39;weekdate&#39; using package &#39;lubridate&#39; mutate(quarter = quarter(weekdate)) %&gt;% # Create dummy variable for quarter 4 mutate(q4=ifelse(quarter==4,1,0)) # Create new data frame with only department 16 dssales.16 &lt;- dssales %&gt;% filter(dept==16) # Run model with intercept shifter only mod.is &lt;- lm(sales~size + q4, data=dssales.16) # Show results using &#39;jtools&#39; package summ(mod.is, digits=4, model.info=FALSE) 2.9.7 Table 2.7 See Table 2.7 # Run model with slope shifter only; use &#39;:&#39; between interaction terms to # exclude main effect of q4 from model mod.ss &lt;- lm(sales~size+size:q4, data=dssales.16) # Show results using &#39;jtools&#39; package summ(mod.ss, digits=4, model.info=FALSE) 2.9.8 Table 2.8 See Table 2.8 # Run model with intercept and slope shifter; use &#39;*&#39; between interaction # terms to include interaction AND main effects mod.iss &lt;- lm(sales~size*q4, data=dssales.16) # Show results using &#39;jtools&#39; package summ(mod.iss, digits=4, model.info=FALSE) 2.9.9 Table 2.9 See Table 2.9 # Make &#39;quarter&#39; a factor variable so R will use dummy variables automatically dssales.16$quarter &lt;- factor(dssales.16$quarter) # Set base level of &#39;quarter&#39; to be 4 dssales.16$quarter &lt;- relevel(dssales.16$quarter, ref=4) # Run model with multiple dummies for quarter mod.mis &lt;- lm(sales~size+quarter, data=dssales.16) # Show results using &#39;jtools&#39; package summ(mod.mis, digits=4, model.info=FALSE) 2.9.10 Figure 2.1 See Figure 2.1 # Use package GGally::ggpairs to easily create combination correlation # and scatterplot matrix ggpairs(lrreg1, # Dataset lower=list(continuous= wrap(&quot;smooth&quot;, method=&quot;lm&quot;, se=FALSE, # Add fit line color=&quot;midnightblue&quot;)), # Set dot color diag=list(continuous=&quot;blankDiag&quot;)) # Set diagonals to be blank 2.9.11 Figure 2.2 See Figure 2.2 melt(lrreg1) %&gt;% # Use package &#39;reshape2&#39; to reshape the data for facet plot # Begins plot with each variable as a factor and # value of the variable to be plotted ggplot(aes(factor(variable), value)) + # Requests boxplot as geom function geom_boxplot() + # Adds the whiskers to the boxplot stat_boxplot(geom=&#39;errorbar&#39;) + # Creates a facet/matrix layout based on the variable facet_wrap(~variable, scale=&quot;free&quot;) + # Change text size theme(text=element_text(size=15)) + # Removes axis labels labs(x=&quot;&quot;, y=&quot;&quot;) 2.9.12 Figure 2.3 See Figure 2.3 # Create dataframe for ad_tv prediction using &#39;effects&#39; package lp.adtv &lt;- as.data.frame(predictorEffects(results)$ad_tv) # Create plot and save as object &#39;p1&#39; p1 &lt;- # Begins plot with &#39;ad_tv&#39; on x axis and &#39;fit&#39; on y axis ggplot(aes(x=ad_tv, y=fit), data=lp.adtv) + # Draws line based on predicted points geom_line(color=&quot;darkred&quot;) + # Adds confidence interaval bands around line geom_ribbon(aes(ymin=lower, ymax=upper), fill=&quot;red&quot;, alpha=0.2) + # Next two commands scale x and y axes scale_x_continuous(limits=c(0,300), expand=c(.025,.025), breaks=seq(0,300,50), minor_breaks=NULL) + scale_y_continuous(limits=c(5,30), expand=c(.025,.025), breaks=seq(5,30,5), minor_breaks=NULL) + # Change text size theme(text=element_text(size=15)) + # Labels axes labs(x=&quot;TV Advertising (ad_tv)&quot;, y=&quot;Linear Prediction&quot;) # Repeat for other two variables lp.adrad &lt;- as.data.frame(predictorEffects(results)$ad_radio) p2 &lt;- ggplot(aes(x=ad_radio, y=fit), data=lp.adrad) + geom_line(color=&quot;darkgreen&quot;) + geom_ribbon(aes(ymin=lower, ymax=upper), fill=&quot;green&quot;, alpha=0.2) + scale_x_continuous(limits=c(0,50), expand=c(.025,.025), breaks=seq(0,50,10), minor_breaks=NULL) + scale_y_continuous(limits=c(5,30), expand=c(.025,.025), breaks=seq(5,30,5), minor_breaks=NULL) + theme(text=element_text(size=15)) + labs(x=&quot;Radio Advertising (ad_radio)&quot;, y=&quot;Linear Prediction&quot;) lp.adpap &lt;- as.data.frame(predictorEffects(results)$ad_paper) p3 &lt;- ggplot(aes(x=ad_paper, y=fit), data=lp.adpap) + geom_line(color=&quot;darkorange&quot;) + geom_ribbon(aes(ymin=lower, ymax=upper), fill=&quot;orange&quot;, alpha=0.2) + scale_x_continuous(limits=c(0,115), expand=c(.025,.025), breaks=seq(0,115,20), minor_breaks=NULL) + scale_y_continuous(limits=c(5,30), expand=c(.025,.025), breaks=seq(5,30,5), minor_breaks=NULL) + theme(text=element_text(size=15)) + labs(x=&quot;Newspaper Advertising (ad_paper)&quot;, y=&quot;Linear Prediction&quot;) # Arrange three plots in a grid using package &#39;cowplot&#39; plot_grid(p1,p2,p3) 2.9.13 Figure 2.4 See Figure 2.4 # Create new data for prediction with &#39;ad_tv&#39; as focus ad.tv.pred &lt;- crossing(ad_tv=seq(0,300,30), # 11 levels ad_radio=seq(0,50,10)) # 6 levels # Append linear prediction and prediction intervals to new data ad.tv.pred$pred &lt;- as.data.frame( predict.lm(resultssig, # Model to use for prediction ad.tv.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals # Create plot and save as object &#39;p1&#39; p1 &lt;- # Begins plot ggplot(aes(x=ad_tv, # levels of &#39;ad_tv&#39; for x-axis y=pred$fit, # linear prediction for y-axis group=as.factor(ad_radio), # different geoms for each level of &#39;ad_radio&#39; color=as.factor(ad_radio)), # different colors for each level of &#39;ad_radio&#39; data=ad.tv.pred) + # Draws lines and points based on predicted values geom_line() + geom_point() + # Adds confidence interaval bands around line geom_errorbar(aes(ymin=pred$lwr, ymax=pred$upr), width=5) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(0,300,50), minor_breaks=NULL) + scale_y_continuous(limits=c(0,30), expand=c(.025,.025), breaks=seq(0,30,5), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + guides(color=guide_legend(title.position=&quot;top&quot;)) + # Labels axes and legend labs(x=&quot;TV Advertising (ad_tv)&quot;, y=&quot;Linear Prediction&quot;, color=&quot;Radio Advertising (ad_radio)&quot;) # Repeat for other variable ad.rad.pred &lt;- crossing(ad_tv=seq(0,300,100), # 4 levels ad_radio=seq(0,50,5)) # 11 levels ad.rad.pred$pred &lt;- as.data.frame( predict.lm(resultssig, ad.rad.pred, interval=&quot;confidence&quot;)) p2 &lt;- ggplot(aes(x=ad_radio, y=pred$fit, group=as.factor(ad_tv), color=as.factor(ad_tv)), data=ad.rad.pred) + geom_line() + geom_point() + geom_errorbar(aes(ymin=pred$lwr, ymax=pred$upr), width=.83) + scale_x_continuous(breaks=seq(0,50,10), minor_breaks=NULL) + scale_y_continuous(limits=c(0,30), expand=c(.025,.025), breaks=seq(0,30,5), minor_breaks=NULL) + theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + guides(color=guide_legend(title.position=&quot;top&quot;)) + labs(x=&quot;Radio Advertising (ad_radio)&quot;, y=&quot;Linear Prediction&quot;, color=&quot;TV Advertising (ad_tv)&quot;) # Arrange three plots in a grid using package &#39;cowplot&#39; plot_grid(p1,p2) 2.9.14 Figure 2.5 See Figure 2.5 # Create new data for prediction with &#39;size&#39; as focus size.pred &lt;- crossing(size=seq(70000,220000,15000), # 11 levels q4=0:1) # dummy variable # Append linear prediction and prediction intervals to new data size.pred$pred &lt;- as.data.frame( predict.lm(mod.is, # Model to use for prediction size.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals # Begins plot ggplot(aes(x=size, # levels of &#39;size&#39; for x-axis y=pred$fit, # linear prediction for y-axis color=as.factor(q4)), # different colors for each level of &#39;q4&#39; data=size.pred) + # Draws lines based on predicted values geom_line(size=1) + # Adds confidence interval bands around line geom_ribbon(aes(ymin=pred$lwr, ymax=pred$upr, fill=as.factor(q4)), alpha=0.2) + # Next two commands set colors for lines and CI fill scale_color_manual(name=&quot;Q4&quot;, values=c(&quot;darkred&quot;, &quot;darkblue&quot;)) + scale_fill_manual(name=&quot;Q4&quot;, values=c(&quot;red&quot;, &quot;blue&quot;)) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(70000,220000,30000), minor_breaks=NULL) + scale_y_continuous(limits=c(-5000,25000), expand=c(.025,.025), breaks=seq(-5000,25000,10000), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + # Labels axes and legend labs(x=&quot;Size&quot;, y=&quot;Linear Prediction&quot;) 2.9.15 Figure 2.6 See Figure 2.6 # Create new data for prediction with &#39;size&#39; as focus size.pred &lt;- crossing(size=seq(70000,220000,15000), # 11 levels q4=0:1) # dummy variable # Append linear prediction and prediction intervals to new data size.pred$pred &lt;- as.data.frame( predict.lm(mod.ss, # Model to use for prediction size.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals # Begins plot ggplot(aes(x=size, # levels of &#39;size&#39; for x-axis y=pred$fit, # linear prediction for y-axis color=as.factor(q4)), # different colors for each level of &#39;q4&#39; data=size.pred) + # Draws lines based on predicted values geom_line(size=1) + # Adds confidence interval bands around line geom_ribbon(aes(ymin=pred$lwr, ymax=pred$upr, fill=as.factor(q4)), alpha=0.2) + # Next two commands set colors for lines and CI fill scale_color_manual(name=&quot;Q4&quot;, values=c(&quot;darkred&quot;, &quot;darkblue&quot;)) + scale_fill_manual(name=&quot;Q4&quot;, values=c(&quot;red&quot;, &quot;blue&quot;)) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(70000,220000,15000), minor_breaks=NULL) + scale_y_continuous(limits=c(-5000,25000), expand=c(.025,.025), breaks=seq(-5000,25000,10000), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + # Labels axes and legend labs(x=&quot;Size&quot;, y=&quot;Linear Prediction&quot;) 2.9.16 Figure 2.7 See Figure 2.7 # Create new data for prediction with &#39;size&#39; as focus size.pred &lt;- crossing(size=seq(0,220000,20000), # 11 levels q4=0:1) # dummy variable # Append linear prediction and prediction intervals to new data size.pred$pred &lt;- as.data.frame( predict.lm(mod.iss, # Model to use for prediction size.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals ggplot(aes(x=size, # levels of &#39;size&#39; for x-axis y=pred$fit, # linear prediction for y-axis color=as.factor(q4)), # different colors for each level of &#39;q4&#39; data=size.pred) + # Draws lines based on predicted values geom_line(size=1) + # Next two commands set colors for lines and CI fill scale_color_manual(name=&quot;Q4&quot;, values=c(&quot;darkred&quot;, &quot;darkblue&quot;)) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(0,220000,55000), minor_breaks=NULL) + scale_y_continuous(limits=c(-10000,25000), expand=c(.025,.025), breaks=seq(-5000,25000,10000), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + # Labels axes and legend labs(x=&quot;Size&quot;, y=&quot;Linear Prediction&quot;) 2.9.17 Figure 2.8 See Figure 2.8 # Create new data for prediction with &#39;size&#39; as focus size.pred &lt;- crossing(size=seq(70000,220000,15000), # 11 levels q4=0:1) # dummy variable # Append linear prediction and prediction intervals to new data size.pred$pred &lt;- as.data.frame( predict.lm(mod.iss, # Model to use for prediction size.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals ggplot(aes(x=size, # levels of &#39;size&#39; for x-axis y=pred$fit, # linear prediction for y-axis color=as.factor(q4)), # different colors for each level of &#39;q4&#39; data=size.pred) + # Draws lines based on predicted values geom_line(size=1) + # Adds confidence interval bands around line geom_ribbon(aes(ymin=pred$lwr, ymax=pred$upr, fill=as.factor(q4)), alpha=0.2) + # Next two commands set colors for lines and CI fill scale_color_manual(name=&quot;Q4&quot;, values=c(&quot;darkred&quot;, &quot;darkblue&quot;)) + scale_fill_manual(name=&quot;Q4&quot;, values=c(&quot;red&quot;, &quot;blue&quot;)) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(70000,220000,30000), minor_breaks=NULL) + scale_y_continuous(limits=c(-5000,25000), expand=c(.025,.025), breaks=seq(-5000,25000,10000), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + # Labels axes and legend labs(x=&quot;Size&quot;, y=&quot;Linear Prediction&quot;) 2.9.18 Figure 2.9 See Figure 2.9 # Create new data for prediction with &#39;size&#39; as focus size.pred &lt;- crossing(size=seq(0,240000,20000), # 13 levels quarter=1:4) # dummy variable # Set &#39;quarter&#39; to be factor variable to match model size.pred$quarter &lt;- as.factor(size.pred$quarter) # Append linear prediction and prediction intervals to new data size.pred$pred &lt;- as.data.frame( predict.lm(mod.mis, # Model to use for prediction size.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals # Begins plot ggplot(aes(x=size, # levels of &#39;size&#39; for x-axis y=pred$fit, # linear prediction for y-axis color=quarter), # different colors for each level of &#39;quarter&#39; data=size.pred) + # Draws lines based on predicted values geom_line(size=1) + # Adds confidence interval bands around line geom_ribbon(aes(ymin=pred$lwr, ymax=pred$upr, fill=quarter), alpha=0.2) + # Next two commands set colors for lines and CI fill scale_color_manual(name=&quot;Quarter&quot;, values=c(&quot;darkred&quot;, &quot;darkblue&quot;, &quot;darkgreen&quot;, &quot;darkorange&quot;)) + scale_fill_manual(name=&quot;Quarter&quot;, values=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;orange&quot;)) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(0,240000,40000), minor_breaks=NULL) + scale_y_continuous(limits=c(-10000,45000), expand=c(.025,.025), breaks=seq(-10000,40000,10000), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + # Labels axes and legend labs(x=&quot;Size&quot;, y=&quot;Linear Prediction&quot;) 2.9.19 Figure 2.10 See Figure 2.10 # Create new data for prediction with &#39;size&#39; as focus size.pred &lt;- crossing(size=seq(70000,220000,15000), # 11 levels quarter=1:4) # dummy variable # Set &#39;quarter&#39; to be factor variable to match model size.pred$quarter &lt;- as.factor(size.pred$quarter) # Append linear prediction and prediction intervals to new data size.pred$pred &lt;- as.data.frame( predict.lm(mod.mis, # Model to use for prediction size.pred, # Data set to predict on interval=&quot;confidence&quot;)) # Confidence intervals # Begins plot ggplot(aes(x=size, # levels of &#39;size&#39; for x-axis y=pred$fit, # linear prediction for y-axis color=quarter), # different colors for each level of &#39;q4&#39; data=size.pred) + # Draws lines based on predicted values geom_line(size=1) + geom_point() + # Adds confidence interval bands around line scale_color_manual(name=&quot;Quarter&quot;, values=c(&quot;darkred&quot;, &quot;darkblue&quot;, &quot;darkgreen&quot;, &quot;darkorange&quot;)) + # Next two commands scale x and y axes scale_x_continuous(breaks=seq(70000,220000,30000), minor_breaks=NULL) + scale_y_continuous(limits=c(-5000,40000), expand=c(.025,.025), breaks=seq(-5000,40000,5000), minor_breaks=NULL) + # Position legend at bottom with title over legend; change text size theme(legend.position=&quot;bottom&quot;, text=element_text(size=15)) + # Labels axes and legend labs(x=&quot;Size&quot;, y=&quot;Linear Prediction&quot;) "],["logistic-regression.html", "Chapter 3 Logistic Regression 3.1 Motivation 3.2 R Packages and Datasets for Topic 2 3.3 Why not use linear regression? 3.4 Understanding Logistic Regression 3.5 Conducting Logistic Regression 3.6 Logistic Regression Example 3.7 R Code", " Chapter 3 Logistic Regression 3.1 Motivation Marketers often observe binary outcomes Did a customer: purchase? subscribe? renew? respond? Using linear regression is not appropriate But logistic regression still allows us to: Understand IV/DV relationships Make predictions 3.2 R Packages and Datasets for Topic 2 library(ggplot2) # Advanced graphing capabilities library(tidyr) # Easier programming library(scales) # Control appearance of axes and legend labels library(flextable) # Better HTML Tables library(htmlTable) # Better HTML Tables library(reshape2) # Easily convert wide data to long data library(GGally) # ggplot extension; for scatterplot matrix library(summarytools) # Summary statistics library(cowplot) # Arrange separate plots in a grid library(ggtext) # Annotate ggplots library(lubridate) # Easily work with dates library(jtools) # Concise regression results library(dplyr) # Easier programming library(caret) # Create data partitions library(tibble) # load(&quot;Topic03/directmktg.rdata&quot;) source(&quot;Topic03/or_table.R&quot;) source(&quot;Topic03/logreg_cm.R&quot;) source(&quot;Topic03/logreg_roc.R&quot;) source(&quot;Topic03/gainlift.R&quot;) Download directmktg.rdata 3.3 Why not use linear regression? Want to see how \\(age\\) affects \\(buy\\) \\(buy=\\begin{cases}1\\text{ if yes/true}\\\\0\\text{ if no/false}\\end{cases}\\) Examine relationship with a scatterplot What do we see? Figure 3.1: Scatterplot with binary DV (R code) Try linear regression: \\(buy=\\alpha+\\beta_1 age\\) Table 3.1: Linear Regression Results (R code) F(1,398) 251.7421 R² 0.3874 Adj. R² 0.3859 Est. S.E. t val. p (Intercept) -0.7154 0.0702 -10.1930 0.0000 age 0.0285 0.0018 15.8664 0.0000 Standard errors: OLS Good \\(R^2\\) and \\(age\\) is highly significant So whats the problem? Predict \\(buy\\) from linear regression results: \\(\\hat{buy}=-.7154+.0285age\\) Prediction line shown in plot Figure 3.2: Predicted Values from Linear Regression (R code) Add \\(age\\) categories and plot mean \\(buy\\) for each category What shape does this resemble? Can we use this shape to model the relationship? Figure 3.3: Buy for Age Groups (R code) 3.4 Understanding Logistic Regression Uses the logistic function: \\(f(z)=\\frac{e^u}{1+e^u}\\) \\(f(z)\\) is the probability of event happening \\(u\\) is a linear function, such as: \\(\\alpha+\\beta x\\) Ensures predictions are never above 1 or below 0 Figure 3.4: Logistic Function (R code) Probability of event success vs. failure \\(=\\frac{f(z)}{1-f(z)}=\\) Odds Ratio (\\(OR\\)) Suppose probability of success \\(=.01\\), then: \\(OR=\\frac{.01}{1-.01}=.0101\\) Suppose probability of success \\(=.001\\), then: \\(OR=\\frac{.001}{1-.001}=.0010\\) Suppose probability of success \\(=.99\\), then: \\(OR=\\frac{.99}{1-.99}=99\\) Suppose probability of success \\(=.999\\), then: \\(OR=\\frac{.999}{1-.999}=999\\) Suppose probability of success \\(=.5\\), then: \\(OR=\\frac{.5}{1-.5}=1\\) Substituting logistic function for \\(f(z)\\) into Odds Ratio \\(\\Rightarrow\\) \\(OR=e^u=e^{\\alpha+betax}\\) \\(\\frac{f(z)}{1-f(z)}=\\frac{\\frac{e^u}{1+e^u}}{1-\\frac{e^u}{1+e^u}}=\\frac{\\frac{e^u}{1+e^u}}{\\frac{1+e^u}{1+e^u}-\\frac{e^u}{1+e^u}}=\\frac{\\frac{e^u}{1+e^u}}{\\frac{1}{1+e^u}}=e^u\\) Can transform exponential function into linear \\(\\Rightarrow\\) \\(Logit=\\ln(OR)=\\alpha+\\beta x\\) 3.5 Conducting Logistic Regression Model Estimation Assessing Model Fit Goodness of Fit Measures Classification Matrix ROC Curve Interpreting Coefficients Gains and Lift 3.5.1 Model Estimation Best to use training data and holdout data Estimate model on training data (~75% of sample) Check prediction accuracy on holdout data (~25%) Can estimate either (1) \\(OR\\) or (2) \\(Logit\\) formulation \\(OR=e^{\\alpha+\\beta_1x_1+\\cdots+\\beta_kx_k}\\) \\(Logit=\\alpha+\\beta_1x_1+\\cdots+\\beta_kx_k\\) Independent variables: Can be one or more Can be continuous or categorical/factor 3.5.2 Assessing Model Fit 3.5.2.1 Goodness-of-Fit Measures Overall significance based on \\(-2LL\\) Lower (closer to \\(0\\)) \\(-2LL\\) indicates a better fit Compare \\(-2LL\\) of estimated model with null model McFaddens Pseudo-\\(R^2\\) Values range from 0 to 1 like linear regression Interpreted in a similar manner Amount of variation in DV explained by IVs 3.5.2.2 Classification Matrix How does the model do in predicting outcomes? Generate predicted probability of success, \\(p(\\text{SUCCESS})\\), for each observation If \\(p(\\text{SUCCESS})\\ge0.5\\), predict \\(\\text{SUCCESS}=1\\) If \\(p(\\text{SUCCESS})&lt;0.5\\), predict \\(\\text{SUCCESS}=0\\), or \\(\\text{FAILURE}\\) Check predictions against actual outcomes Examine both training and holdout data Figure 3.5: Classification Matrix Three main measures Sensitivity: Predicted success given actual success \\(p(\\hat{+}|+)=a/(a+c)\\) Specificity: Predicted failure given actual failure \\(p(\\hat{-}|-)=d/(b+d)\\) Overall correctly classified \\((a+d)/(a+b+c+d)\\) Sensitivity vs. Specificity Ideally, want both to be high, but the \\(p(\\text{SUCCESS})\\ge\\pi\\) threshold can be changed Why change \\(\\pi\\)? Avoid false positives or negatives By default: Increasing sensitivity decreases specificity Increasing specificity decreases sensitivity Overall correctly classified Compare with Proportional Chance Criterion (\\(PCC\\)) \\(PCC\\) is the average probability of classification based on group sizes \\(PCC=p^2+(1-p)^2\\) where \\(p\\) is the proportion of sample in the \\(\\text{SUCCESS}\\) group Overall correctly classified \\(&gt;PCC\\) considered good fit when examining holdout data 3.5.2.3 ROC Curve Plot sensitivity by \\(1-\\) specificity as \\(\\pi\\) goes from \\(0\\) to \\(1\\) More area under curve means better model Area under Curve Discrimination AUC = .5 None .5 &lt; AUC &lt; .7 Poor .7  AUC &lt; .8 Acceptable .8  AUC &lt; .9 Excellent AUC  .9 Outstanding Figure 3.6: Sample ROC Curve 3.5.3 Interpreting Coefficients Relationship between DV and each IV \\(H_0: \\beta_k=0\\) vs. \\(H_a: \\beta_k\\ne0\\) Interpret significant relationships Interpretation depends on \\(OR\\) or \\(Logit\\) estimation Direction of relationship: \\(Logit\\) estimation: \\(\\beta_k&gt;0\\) for positive, \\(\\beta_k&lt;0\\) for negative \\(OR\\) estimation: \\(\\beta_k&gt;1\\) for positive, \\(\\beta_k&lt;1\\) for negative Magnitude of change: \\(Logit\\) estimation: coefficients are not particularly useful \\(OR\\) estimation: Percentage change in odds Compare probabilities between groups 3.5.4 Gain and Lift Evaluate performance of classification Example: Suppose \\(10\\%\\) of \\(2000\\) customers will accept offer For \\(100\\) random customers, expect \\(10\\) accepted offers Model predicts some customers more likely to accept Instead of contacting \\(100\\) random customersContact \\(100\\) most likely to accept based on model Continue doing this in groups of \\(100\\) (or \\(200\\), etc.) Gain and lift provide measures of how much better the model performs vs. no model/random Process Predict $p() for each observation and sort descending Split into 10 (deciles) or 20 (demi-deciles) ordered groups Calculate \\(\\%\\) observations and \\(\\%\\) successes for each group 3.5.4.1 Gain Cumulative successes up to that group divided by total successes across all groups Plot on \\(y\\)-axis, with cumulative percent of observations on \\(x\\)-axis Figure 3.7: Typical Gain Chart Shape 3.5.4.2 Lift Ratio of cumulative success up to that group divided by expected success from no model Plot on \\(y\\)-axis, with cumulative percent of observations on \\(x\\)-axis Figure 3.8: Typical Lift Chart Shape 3.6 Logistic Regression Example 3.6.1 Overview Purchase data for direct marketing campaign 400 observations of individual responses DV: Purchase made, \\(buy\\) (factor: Yes, No) IVs: Age, \\(age\\) Estimated Salary ($000s), \\(salary\\) Gender, \\(gender\\) (factor: Male, Female) Predict likelihood of purchase 3.6.2 Estimation Results Logit formulation results Table 3.2: Logistic Regression Results (Logit Formulation) (R code) ²(3) 182.2574 Pseudo-R² (Cragg-Uhler) 0.6231 Pseudo-R² (McFadden) 0.4638 AIC 218.6842 BIC 233.5126 Est. S.E. z val. p (Intercept) -13.1661 1.6217 -8.1187 0.0000 age 0.2502 0.0321 7.7961 0.0000 salary 0.0406 0.0067 6.0265 0.0000 genderFemale -0.4069 0.3498 -1.1631 0.2448 Standard errors: MLE Odds Ratio Coefficients Table 3.3: Logistic Regression Odds Ratio Coefficients (R code) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b21d34d0{}.cl-b21634be{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b21634bf{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b21634c0{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b2168298{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b2168299{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b216829a{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b216829b{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b216829c{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b216829d{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} ParameterOR Est2.5%97.5%(Intercept)0.00000.00000.0000age1.28431.21251.3760salary1.04151.02861.0563genderFemale0.66570.33141.3130 3.6.3 Overall Model Fit Based on the likelihood ratio \\(\\chi^2\\) test with a \\(p\\text{-value}&lt;.0001\\), the overall model is significant (see Table 3.2) McFaddens Pseudo-\\(R^2\\) of \\(.464\\) means that the model explains about \\(46\\%\\) of the variation between buyers/non-buyers (see Table 3.2) Classification Matrix for the Training Sample shows: High sensitivity (\\(72.2\\%\\)) High specificity (\\(91.2\\%\\)) Correctly classified (\\(84.4\\%\\)) &gt; PCC (\\(54.0\\%\\)) Table 3.4: Classification Matrix for Training Data (R code) Confusion Matrix and Statistics Reference Prediction No Yes No 176 30 Yes 17 78 Accuracy : 0.8439 95% CI : (0.7978, 0.883) No Information Rate : 0.6412 P-Value [Acc &gt; NIR] : 4.55e-15 Kappa : 0.6514 Mcnemar&#39;s Test P-Value : 0.08005 Sensitivity : 0.7222 Specificity : 0.9119 Pos Pred Value : 0.8211 Neg Pred Value : 0.8544 Prevalence : 0.3588 Detection Rate : 0.2591 Detection Prevalence : 0.3156 Balanced Accuracy : 0.8171 &#39;Positive&#39; Class : Yes PCC = 53.99% Classification Matrix for the Test/Holdout Sample shows: High sensitivity (\\(77.1\\%\\)) High specificity (\\(90.6\\%\\)) Correctly classified (\\(85.9\\%\\)) &gt; PCC (\\(54.3\\%\\)) Table 3.5: Classification Matrix for Test/Holdout Data (R code) Confusion Matrix and Statistics Reference Prediction No Yes No 58 8 Yes 6 27 Accuracy : 0.8586 95% CI : (0.7741, 0.9205) No Information Rate : 0.6465 P-Value [Acc &gt; NIR] : 2.004e-06 Kappa : 0.6866 Mcnemar&#39;s Test P-Value : 0.7893 Sensitivity : 0.7714 Specificity : 0.9062 Pos Pred Value : 0.8182 Neg Pred Value : 0.8788 Prevalence : 0.3535 Detection Rate : 0.2727 Detection Prevalence : 0.3333 Balanced Accuracy : 0.8388 &#39;Positive&#39; Class : Yes PCC = 54.29% ROC Curve for Training Sample Area \\(&gt;.90\\) suggests an outstanding model fit Figure 3.9: ROC Curve fro Training Data (R code) ROC Curve for Training Sample Area \\(&gt;.90\\) suggests an outstanding model fit Figure 3.10: ROC Curve fro Test/Holdout Data (R code) 3.6.4 Interpreting Coefficients \\(age\\) is positive (\\(OR&gt;1\\)) and significant (\\(p&lt;.001\\)) \\(1\\) year increase in \\(age\\) increases odds of buying by a factor of \\(1.28\\) (or odds of buying increase by \\(25\\%\\)) \\(salary\\) is positive (\\(OR&gt;1\\)) and significant (\\(p&lt;.001\\)) \\(\\$1000\\) increase in \\(salary\\) increases odds of buying by a factor of \\(1.04\\) (or odds of buying increase by \\(4\\%\\)) \\(gender\\) is negative (\\(OR&lt;1\\)), but not significant (\\(p=.245\\)) Had it been significant Being female decreases odds of buying by a factor of \\(.67\\) (or odds of buying decrease by \\(33\\%\\)) Can visually examine how \\(\\Pr(buy)\\) changes with a variable for continuous IVs Factor variables can be separate lines (see 3.11 or separate plots (see 3.12 Figure 3.11: Margin Plot for Age (Separate Lines for Gender) (R code) Figure 3.12: Margin Plot for Age (Separate Plots for Gender) (R code) Can create different lines for specific levels of another continuous IV See @ref(fig:t3mpage03 for \\(age\\) with different levels of \\(salary\\) See @ref(fig:t3mpage04 for \\(salary\\) with different levels of \\(age\\) Figure 3.13: Margin Plot for Age at at Different Levels of Salary (R code) Figure 3.14: Margin Plot for Salary at at Different Levels of Age (R code) 3.6.5 Gain Can examine gain for both the training and holdout samples But using holdout is more informative Contacting the top \\(25\\%\\) of predicted buyers yields nearly \\(60\\%\\) of actual buyers Table 3.6: Gain Table for Training and Test/Holdout Data (R code) # A tibble: 20 x 3 `% Sample` Holdout Training &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.05 0.114 0.130 2 0.1 0.2 0.25 3 0.15 0.343 0.370 4 0.2 0.486 0.481 5 0.25 0.6 0.593 6 0.3 0.743 0.713 7 0.35 0.771 0.778 8 0.4 0.829 0.843 9 0.45 0.914 0.907 10 0.5 0.971 0.935 11 0.55 1 0.981 12 0.6 1 0.991 13 0.65 1 0.991 14 0.7 1 0.991 15 0.75 1 1 16 0.8 1 1 17 0.85 1 1 18 0.9 1 1 19 0.95 1 1 20 1 1 1 Figure 3.15: Gain Chart for Training and Test/Holdout Data (R code) 3.6.6 Lift Can examine gain for both the training and holdout samples But using holdout is more informative Contacting the top \\(25\\%\\) of predicted buyers provides lift of nearly Table 3.7: Lift Table for Training and Test/Holdout Data (R code) # A tibble: 20 x 3 `% Sample` Holdout Training &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.05 2.83 2.60 2 0.1 2.2 2.51 3 0.15 2.42 2.48 4 0.2 2.53 2.42 5 0.25 2.48 2.38 6 0.3 2.54 2.38 7 0.35 2.25 2.23 8 0.4 2.10 2.11 9 0.45 2.06 2.02 10 0.5 1.96 1.88 11 0.55 1.83 1.79 12 0.6 1.68 1.66 13 0.65 1.55 1.53 14 0.7 1.43 1.42 15 0.75 1.34 1.34 16 0.8 1.25 1.25 17 0.85 1.18 1.18 18 0.9 1.11 1.11 19 0.95 1.05 1.06 20 1 1 1 Figure 3.16: Lift Chart for Training and Test/Holdout Data (R code) 3.7 R Code Figure 3.1 directmktg %&gt;% mutate(buy01=as.numeric(buy)-1) %&gt;% # Change &#39;buy&#39; to 0-1 ggplot(aes(x=age, y=buy01)) + geom_point(size=2) + labs(x=&quot;Age&quot;, y=&quot;Buy&quot;) Figure 3.2 directmktg %&gt;% select(age) %&gt;% # Select only the age variable mutate(yhat=predict.lm(model,.)) %&gt;% # Predict y from model # Next line creates variable to highlight negative predictions mutate(neg=as.factor(ifelse(yhat&lt;0,&quot;Yes&quot;,&quot;No&quot;))) %&gt;% ggplot(aes(x=age, y=yhat, color=neg)) + geom_point(size=3) + scale_color_manual(values=c(&quot;Yes&quot;=&quot;red&quot;, # Manually set point colors &quot;No&quot;=&quot;black&quot;), guide=&quot;none&quot;) + labs(x=&quot;Age&quot;, y=&quot;Linear Prediction&quot;) Figure 3.3 # Create data frame grouped by age dmgrp &lt;- directmktg %&gt;% # &#39;cut&#39; breaks a continuous variable into groups of each width # &#39;as.numeric&#39; keeps the new variable as integer (vs. factor) mutate(agegrp = as.numeric(cut(age, 9))) %&gt;% group_by(agegrp) %&gt;% summarise(age=mean(age), buy=mean(as.numeric(buy)-1)) # Run logistic model to create prediction to make s-curve binmod &lt;- glm(buy~age, directmktg, family=&quot;binomial&quot;) # Create dataframe with predicted values dmpred &lt;- directmktg %&gt;% select(age, buy) %&gt;% mutate(yhat=predict(binmod, type=&quot;response&quot;), buy=as.numeric(buy)-1) # Create combined plot; each geom with separate data ggplot() + geom_point(data=directmktg, aes(x=age, y=(as.numeric(buy)-1)), size=3, color=&quot;red&quot;) + geom_line(data=dmgrp, aes(x=age, y=buy), size=1.5, color=&quot;midnightblue&quot;) + geom_line(data=dmpred, aes(x=age, y=yhat), size=1.5, color=&quot;darkorange&quot;) + theme(text=element_text(size=15)) + labs(x=&quot;Age&quot;, y=&quot;Buy&quot;) Figure 3.4 # Create simulated data frame based on logistic function u=seq(-7,7,.05) fz=exp(u)/(1+exp(u)) ufz=data.frame(u=u, fz=fz) # Plot function ufz %&gt;% ggplot(aes(x=u, y=fz)) + geom_line(color=&quot;darkorange&quot;, size=1.5) + theme(text=element_text(size=15), panel.grid.major.x = element_blank()) + scale_x_continuous(breaks=0, minor_breaks=NULL) + scale_y_continuous(breaks=seq(0,1,1), minor_breaks=NULL) + labs(x=&quot;u&quot;, y=&quot;f(z)&quot;) Figure 3.9 # Use the &#39;logreg_roc.R&#39; user-defined script # It was loaded above with the packages # Requires package &#39;pROC&#39; and &#39;ggplot2 logreg_roc(model, # Object with model results train) # Data to use (i.e., training vs. testing) Figure 3.10 # Use the &#39;logreg_roc.R&#39; user-defined script # It was loaded above with the packages # Requires package &#39;pROC&#39; and &#39;ggplot2 logreg_roc(model, # Object with model results test) # Data to use (i.e., training vs. testing) Figure 3.11 # Create new data for prediction with &#39;age&#39; as focus # This will be used for the next two figures age.pred &lt;- crossing(age=seq(18,60,2), salary=mean(train$salary), gender=c(&quot;Male&quot;, &quot;Female&quot;)) # Create data frame with predicted values and confidence bands train.pred &lt;- # &#39;cbind&#39; combines objects by columns cbind(age.pred, predict(model, # Model to predict values with age.pred, # New data to use for IVs type=&quot;link&quot;, # Return log-odds predictions se=TRUE)) %&gt;% # Get std.err. for CIs mutate(pred=plogis(fit), # Calculate pr(buy) upr=plogis(fit+(qnorm(0.975)*se.fit)), # Upper CI lwr=plogis(fit-(qnorm(0.975)*se.fit)), # Lower CI gender=as.factor(gender)) # Save gender as factor # Create plot with gender on same plot ggplot(aes(x=age, y=pred), data=train.pred2) + geom_line(aes(color=gender), size=1) + geom_ribbon(aes(ymin=lwr, ymax=upr, color=gender, fill=gender), alpha=.2) + theme(legend.position=&quot;none&quot;, plot.caption=element_text(size=8)) + scale_color_manual(values=c(&quot;red4&quot;, &quot;navy&quot;)) + scale_fill_manual(values=c(&quot;pink&quot;, &quot;cyan&quot;)) + labs(x=&quot;Age&quot;, y=&quot;Pr(Buy)&quot;, caption=&quot;Calculated at mean value of salary&quot;) Figure 3.12 # Create plot with gender on same plot ggplot(aes(x=age, y=pred), data=train.pred) + geom_line(aes(color=gender), size=1) + geom_ribbon(aes(ymin=lwr, ymax=upr, color=gender, fill=gender), alpha=.2) + facet_grid(~gender) + theme(legend.position=&quot;none&quot;, plot.caption=element_text(size=8)) + scale_color_manual(values=c(&quot;red4&quot;, &quot;navy&quot;)) + scale_fill_manual(values=c(&quot;pink&quot;, &quot;cyan&quot;)) + labs(x=&quot;Age&quot;, y=&quot;Pr(Buy)&quot;, caption=&quot;Calculated at mean value of salary&quot;) Figure 3.13 # Create new data for prediction with &#39;age&#39; as focus msal &lt;- mean(train$salary) # Assign for less clutter below sdsal &lt;- sd(train$salary) # Assign for less clutter below age.pred &lt;- crossing(age=seq(18,60,2), salary=c(msal-1.5*sdsal, # Mean-1.5SD msal, # Mean msal+1.5*sdsal), # Mean+1.5SD gender=c(&quot;Male&quot;, &quot;Female&quot;)) # Create data frame with predicted values and confidence bands train.pred &lt;- # &#39;cbind&#39; combines objects by columns cbind(age.pred, predict(model, # Model to predict values with age.pred, # New data to use for IVs type=&quot;link&quot;, # Return log-odds predictions se=TRUE)) %&gt;% # Get std.err. for CIs mutate(pred=plogis(fit), # Calculate pr(buy) upr=plogis(fit+(qnorm(0.975)*se.fit)), # Upper CI lwr=plogis(fit-(qnorm(0.975)*se.fit)), # Lower CI gender=as.factor(gender), # Factor for plot salary=as.factor(round(salary,0))) # Factor for plot ggplot(aes(x=age, y=pred), data=train.pred) + geom_line(aes(color=salary), size=1) + geom_ribbon(aes(ymin=lwr, ymax=upr, color=salary, fill=salary), alpha=.2) + facet_grid(.~gender) + # Create separate plots for gender theme(text=element_text(size=15), legend.position=&quot;bottom&quot;) + scale_color_manual(&quot;Salary&quot;, values=c(&quot;red4&quot;, &quot;navy&quot;, &quot;forestgreen&quot;), labels=c(&quot;Mean-1.5SD&quot;, &quot;Mean&quot;, &quot;Mean+1.5SD&quot;)) + scale_fill_manual(&quot;Salary&quot;, values=c(&quot;pink&quot;, &quot;cyan&quot;, &quot;lawngreen&quot;), labels=c(&quot;Mean-1.5SD&quot;, &quot;Mean&quot;, &quot;Mean+1.5SD&quot;)) + labs(x=&quot;Age&quot;, y=&quot;Pr(Buy)&quot;) Figure 3.14 # Create new data for prediction with &#39;age&#39; as focus mage &lt;- mean(train$age) # Assign for less clutter below sdage &lt;- sd(train$age) # Assign for less clutter below sal.pred &lt;- crossing(salary=seq(15,150,5), age=c(mage-1.5*sdage, # Mean-1.5SD mage, # Mean mage+1.5*sdage), # Mean+1.5SD gender=c(&quot;Male&quot;, &quot;Female&quot;)) # Create data frame with predicted values and confidence bands train.pred &lt;- # &#39;cbind&#39; combines objects by columns cbind(sal.pred, predict(model, # Model to predict values with sal.pred, # New data to use for IVs type=&quot;link&quot;, # Return log-odds predictions se=TRUE)) %&gt;% # Get std.err. for CIs mutate(pred=plogis(fit), # Calculate pr(buy) upr=plogis(fit+(qnorm(0.975)*se.fit)), # Upper CI lwr=plogis(fit-(qnorm(0.975)*se.fit)), # Lower CI gender=as.factor(gender), # Factor for plot age=as.factor(round(age,0))) # Factor for plot ggplot(aes(x=salary, y=pred), data=train.pred) + geom_line(aes(color=age), size=1) + geom_ribbon(aes(ymin=lwr, ymax=upr, color=age, fill=age), alpha=.2) + facet_grid(.~gender) + # Create separate plots for gender theme(text=element_text(size=15), legend.position=&quot;bottom&quot;) + scale_color_manual(&quot;Age&quot;, values=c(&quot;red4&quot;, &quot;navy&quot;, &quot;forestgreen&quot;), labels=c(&quot;Mean-1.5SD&quot;, &quot;Mean&quot;, &quot;Mean+1.5SD&quot;)) + scale_fill_manual(&quot;Age&quot;, values=c(&quot;pink&quot;, &quot;cyan&quot;, &quot;lawngreen&quot;), labels=c(&quot;Mean-1.5SD&quot;, &quot;Mean&quot;, &quot;Mean+1.5SD&quot;)) + labs(x=&quot;Salary&quot;, y=&quot;Pr(Buy)&quot;) Figure 3.15 # Plot was already returned in the previous call to &#39;gainlift&#39; glresults$gainplot Figure 3.16 # Plot was already returned in the previous call to &#39;gainlift&#39; glresults$gainlift Table 3.1 model &lt;- directmktg %&gt;% mutate(buy=as.numeric(buy)-1) %&gt;% lm(buy ~ age, .) # NOTE: &#39;summ&#39; uses the &#39;jtools&#39; package summ(model, model.info=FALSE, digits=4) # For virtual environment, use &#39;summary&#39; from Base R Table 3.2 # Use &#39;caret&#39; package to create training and test/holdout samples # This will create two separate dataframes: train and test set.seed(4320) inTrain &lt;- createDataPartition(y=directmktg$buy, p=.75, list=FALSE) train &lt;- directmktg[inTrain,] test &lt;- directmktg[-inTrain,] # Estimate the model on the training data model &lt;- glm(buy ~ age + salary + gender, train, family=&quot;binomial&quot;) # NOTE: &#39;summ&#39; uses the &#39;jtools&#39; package summ(model, model.info=FALSE, digits=4) # For virtual environment, use &#39;summary&#39; from Base R Table 3.3 # Use the &#39;or_table.R&#39; user-defined script # It was loaded above with the packages flextable(or_table(model)) Table 3.4 # Use the &#39;logreg_cm.R&#39; user-defined script # It was loaded above with the packages # Requires package &#39;caret&#39; logreg_cm(model, # Object with model results train, # Data to use (i.e., training vs. testing) &quot;Yes&quot;) # Factor level for &quot;True&quot; Table 3.5 # Use the &#39;logreg_cm.R&#39; user-defined script # It was loaded above with the packages # Requires package &#39;caret&#39; logreg_cm(model, # Object with model results test, # Data to use (i.e., training vs. testing) &quot;Yes&quot;) # Factor level for &quot;True&quot; Table 3.6 # Use the &#39;gainlift.R&#39; user-defined script # It was loaded above with the packages # Requires packages &#39;ggplot2&#39;, &#39;dplyr&#39;, and &#39;tidyr&#39; # Returns a list of four things: # gainplot, liftplot, gaintable, lifttable glresults &lt;- gainlift(model, train, test, &quot;Yes&quot;) glresults$gaintable Table 3.7 # Table was already returned in the previous call to &#39;gainlift&#39; glresults$lifttable "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
