```{r echo=FALSE}
knitr::opts_chunk$set(comment=NA)
options(scipen=5)  # Turns off scientific notation
```

# Targeting and Retaining Customers

## R Packages and Datasets for Topic 4

``` {r t4packagesdata, message=FALSE}
library(cowplot)       # Arrange plots in grid
library(ggplot2)       # Advanced graphing capabilities
library(tidyr)         # Easier programming 
library(GGally)        # Scatterplot matrix
library(flextable)     # Better HTML Tables
library(htmlTable)     # Better HTML Tables
library(jtools)        # Concise regression results
library(dplyr)         # Easier programming
library(caret)         # Create data partitions
load("Topic04/bankmktg.rdata")
load("Topic04/telecom.rdata")
```

## Targeting Customers

* One-to-One Marketing
    * Time consuming
    * Costly
* Mass Marketing
    * Customer needs not being met
* Target Marketing
    * Market to those likely to...

### Goal

Target customers with the highest likelihood of a favorable outcome using explanatory variables

* Outcome variable could be:
    * Purchase
    * Sales
    * Costs
    * Profitability
    * CLV
* Explanatory variables could be:
    * Demographics
    * Behaviors
    * Usage
    * Lifestyles
    
The outcome variable will dictate the type of analysis we can perform

* Continuous outcome variables have a meaningful magnitude
    * Use linear regression
* Categorical outcome variables do not have a meaningful magnitude
    * Use logistic regression
    
## Retaining Customers

Importance of retention:

> Reducing defections $5\%$ boosts profits $25\%$ to $85\%$.  â€” Frederick F. Reichheld and W. Earl Sasser, Jr.

### Goal

Identify factors (i.e., independent variables) that increase the likelihood of retention (or decrease the likelihood of churn)

* Retention (or Churn) is the outcome or dependent variable
    * DV = Binary, so Method = Logistic Regression
    
## Targeting Customers (Linear Regression) Example

### Overview

* Customer revenue, usage, and demographics for a cell phone provider
* DV:
    * Mean monthly revenue (prior 6 months), `avg6rev`
* IVs:
    * Mean monthly minutes (prior 6 months), `avg6mou`
    * Mean monthly customer care calls, `cc`
    * Mean monthly directory assistance calls, `da`
    * Mean monthly overage minutes, `ovrmou`
    * Household income (dollars), `income`
    * Own home (Yes; No), `own`
    
### Summarize Data

* Useful to examine data prior to specifying the model
    * Summary Statistics  
    <caption>(\#tab:t4summstat01) Summary Statistics ([R code](#table-reftabt4summstat01))</caption>
    ``` {r t4summstat01, echo=FALSE, message=FALSE}
    library(vtable)
    sumtable(telecom, out="return") %>% kable(caption=NULL)
    ```

    * Scatterplot Matrix (with Correlations)
    ```{r t4scatmat01, echo=FALSE, fig.cap="Scatterplot Matrix with Correlations ([R code](#figure-reffigt4scatmat01))", message=FALSE}
    ggpairs(telecom[,1:6], # Dataset
            lower=list(continuous="smooth"),
        diag=list(continuous="blankDiag"))  # Set diagonals to be blank
    # Reload 'cowplot'
    ```

### Model Specification

* Goal: Determine what behaviors and demographics are associated with high revenue customers
* IVs are expected to be ones that are related to revenue
    * Expect an interaction between home ownership and overage minutes
* Model: $avg6rev=\alpha+\beta_1avg6mou+\beta_2cc+\beta_3da+\beta_4income+\beta_5ovrmou+\beta_6own + \beta_7(ovrmou\times own)$

### Model Interpretation

#### Results

<caption>(\#tab:t4lr01) Linear Regression Results ([R code](#table-reftabt4lr01))</caption>
```{r t4lr01, echo=FALSE}
target <- lm(avg6rev ~ avg6mou + cc + da + income + ovrmou*own,
             data=telecom)
summary(target)

```
$\hat{avg6rev}=33.742+.049avg6mou-1.332cc+1.895da-.013income+.135ovrmou-7.235own+0.066(ovrmou\times own)$

#### Testing Overall Model Significance

* Relationship between DV and combined effects of IVs
* $H_0: \text{all }\beta_k=0$ vs. $H_a: \text{at least one }\beta_k\ne0$
* Use F-statistic to test
* Conclusion:  With a F-statistic of $811.5$ and a $p<.001$, we conclude that at least one $\beta_k$ is significant

#### Assessing overall model fit

* How much variation in the DV is explained by the model
* Use $R^2$ to assess
* Use Adjusted $R^2$ to compare models
* Conclusion: Based on the $R^2$, about $70\%$ of the variance in `avg6rev` is explained by the model

#### Interpret Individual IVs

* Relationship between DV and each IV
* $H_0: \beta_k=0$ vs. $H_a: \beta_k\ne0$
* Interpret significant relationships
    * `avg6mou`
        * With $p<.001$, `avg6mou` has a significant effect on `avg6rev`.
        * A one unit increase in `avg6mou` is predicted to increase `avg6rev` by $.049$ units.
    * `cc`
        * With $p<.001$, `cc` has a significant effect on `avg6rev`.
        * A one unit increase in `cc` is predicted to decrease `avg6rev` by $1.332$ units.
    * `da`
        * With $p<.001$, `da` has a significant effect on `avg6rev`.
        * A one unit increase in `da` is predicted to increase `avg6rev` by $1.895$ units.
    * `ovrmou` and `own` interaction
        * With $p<.001$, the effect of `ovrmou` on `avg6rev` is significantly different based on `own`.
        * When the customer owns their home, a one unit increase in `ovrmou` is predicted to increase `avg6rev` by $.201$ units.
        * When the customer does notown their home, a one unit increase in `ovrmou` is predicted to increase `avg6rev` by $.135$ units.
    
* Sometimes helps to visually examine the IVs for interpretation
* Plots can show predicted DV at different levels of IVs 

    ```{r t4marginplots01, echo=FALSE, fig.cap="Margin Plots for Significant IVs (No Interaction) ([R code](#figure-reffigt4marginplots01))"}
    # Use package 'effects'
    library(effects)
    
    # Create data frame of values to be plotted for 'avg6mou' as focal
    a6.p <- data.frame(predictorEffect("avg6mou", target, 
                                       focal.levels=seq(0,1500,30)))
    
    # Create plot and assign to p1
    
    p1 <- a6.p %>%
      ggplot(aes(x=avg6mou, y=fit)) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
        labs(x="Mean Monthly Minutes", y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
    
    # Repeat for other Significant IVs
    cc.p <- data.frame(predictorEffect("cc", target,
                                       focal.levels=seq(0,10,.2)))
    p2 <- cc.p %>%
      ggplot(aes(x=cc, y=fit)) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
        labs(x="Mean Monthly Customer Care Calls", y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
    
    da.p <- data.frame(predictorEffect("da", target,
                                       focal.levels=seq(0,10,.2)))
    p3 <- da.p %>%
      ggplot(aes(x=da, y=fit)) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
        labs(x="Mean Monthly Directory Assistance Calls", y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))

    plot_grid(p1, p2, p3, nrow=2)
    ```
    ```{r t4marginplots01b, echo=FALSE, fig.cap="Margin Plots for Interaction ([R code](#figure-reffigt4marginplots01))"}
    om.p <- data.frame(predictorEffect("ovrmou", target,
                                       focal.levels=seq(0,300,6)))
    p4 <- om.p %>%
      ggplot(aes(x=ovrmou, y=fit, color=own, fill=own)) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
        labs(x="Mean Monthly Overage Minutes", y="Linear Prediction",
             color="Homeowner", fill="Homeowner") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15)) +
        theme(legend.position = "bottom")
    
    own.p <- data.frame(predictorEffect("own", target,
                                        xlevels=list(ovrmou=seq(0,300,100))))
    p5 <- own.p %>%
      ggplot(aes(x=own, y=fit, group=1)) +
        geom_point(size=2) +
        geom_line(color="orange") +
        geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
        facet_wrap(~ovrmou) +
        labs(x="Home Ownership", y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
    
    plot_grid(p4, p5, nrow=1)
    ```


    ```{r t4marginplots02, echo=FALSE, fig.cap="Margin Plots for Insignificant IV ([R code](#figure-reffigt4marginplots02))"}
     # Create data frame of values to be plotted for 'avg6mou' as focal
    inc.p <- data.frame(predictorEffect("income", target))
    
    # Create plot
    
    inc.p %>%
      ggplot(aes(x=income, y=fit)) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
        labs(x="Income (000s)", y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
    ```       
* Examine deciles of predicted values by the IVs
    * Split sample into 10 groups based on predicted DV
    * Look at mean values of IVs for each decile  
    
    
    <caption>(\#tab:t4tgtdecile) IVs by Predicted Deciles ([R code](#table-reftabt4tgtdecile))</caption>
    ```{r t4tgtdecile, echo=FALSE}
    telecom %>%
        cbind(., yhat=fitted(target)) %>%  # Append fitted values to data
        mutate(yhat.dec=11-ntile(yhat, 10),  # Create deciles, but reverse order
               own=as.numeric(own)-1) %>%  # Covert own to 1=yes, 0=no
        group_by(yhat.dec) %>%  # Group by decile
        summarise(across(avg6rev:own, 
                    ~mean(.x, na.rm=TRUE))) %>%  # Calculate mean of each IV
        flextable()  # Nice table
    ```

### Conclusion

Recall our Goal:<br>
Determine what behaviors and demographics are associated with high revenue customers

What did we learn?

* We can identify our highest revenue customers by examining `avg6mou`, `cc`, `da`, `ovrmou` and `own`
* Our highest revenue customers consumer over $1000$ minutes per month and have over $200$ overage minutes per month
* More directory assistance calls and fewer customer care calls are associated with higher revenue


## Targeting Customers (Logistic Regression)

### Overview

* Bank marketing data for customers of a bank
* DV:
    * Open term deposit account, `response`
* IVs:
    * Age, `age`
    * Average Yearly Balance, `balance`
    * Housing Loan (Yes, No), `housing`
    * Personal Loan (Yes, No), `loan`
    * Married (Yes, No), `married`
* Predict current customers likely to buy
    * Use training (75%) and holdout (25%) samples

### Estimation Results
    
<caption>(\#tab:t4lrestimation) Logistic Regression Estimation Results on Training Sample ([R code](#table-reftabt4lrestimation))</caption>
``` {r t4lrestimation, echo=FALSE }
# Use 'caret' package to create training and test/holdout samples
library(caret)
# This will create two separate dataframes: train and test
set.seed(9999)
inTrain <- createDataPartition(y=bankmktg$response, p=.75, list=FALSE)
train <- bankmktg[inTrain,]
test <- bankmktg[-inTrain,]

# Estimate using training sample
tgt.log <- glm(response ~ age + balance + housing + loan + married, 
               data=train, family="binomial")
summary(tgt.log)

# Get p-value
p <- with(tgt.log, pchisq(null.deviance - deviance,
                   df.null-df.residual,
                   lower.tail=FALSE))
cat("Model p-value =",sprintf("%.4f",p),"\ ")

# Calculate McFadden's R-sq
Mrsq <- 1-tgt.log$deviance/tgt.log$null.deviance
cat("McFadden's Pseudo-Rsquared = ", round(Mrsq, digits=4))

# Use the 'or_table.R' user-defined script to get Odds Ratio estimates
source("Topic03/or_table.R")
flextable(or_table(tgt.log))
```

### Overall Model Fit

* Based on the likelihood ratio test with p-value < .0001, the overall model is significant
* McFadden's Pseudo-$R^2$ of .030 means that the model explains only about 3% of variation between buyers/non-buyers
* Classification Matrix for Training Sample
* What's the problem?

    <caption>(\#tab:t4cmtrain1) Classification Matrix for Training Sample ([R code](#table-reftabt4cmtrain1))</caption>
    ```{r t4cmtrain1, echo=FALSE, cache=TRUE}
    # Use the 'logreg_cm.R' user-defined script
    source("Topic03/logreg_cm.R")
    # Requires package 'caret', loaded above
    logreg_cm(tgt.log,    # Object with model results
              train,      # Data to use (i.e., training vs. testing)
              "Yes")      # Factor level for "True"
    ```

* Sensitivity/Specificity Plot

    ```{r t4sensspec01, echo=FALSE, fig.cap="Sensitivity/Specificity Plot for Training Sample ([R code](#figure-reffigt4sensspec01))"}
    # Use the 'logreg_cut.R' user-defined script
    source("Topic03/logreg_cut.R")
    logreg_cut(tgt.log, train, "Yes")
    ```

* Classificaiton Matrix for Holdout Sample

    <caption>(\#tab:t4cmtrain2) Classification Matrix for Training Sample with 0.1 Cutoff ([R code](#table-reftabt4cmtrain2))</caption>
    ```{r t4cmtrain2, echo=FALSE, cache=TRUE}
    logreg_cm(tgt.log,    # Object with model results
              train,      # Data to use (i.e., training vs. testing)
              "Yes",      # Factor level for "True"
              0.1)        # New cutoff value
    ```

* Classification Matrix for Holdout Sample
    * Results very similar for holdout sample

    <caption>(\#tab:t4cmtrain3) Classification Matrix for Holdout Sample with 0.1 Cutoff ([R code](#table-reftabt4cmtrain3))</caption>
    ```{r t4cmtrain3, echo=FALSE, cache=TRUE}
    logreg_cm(tgt.log,    # Object with model results
              test,      # Data to use (i.e., training vs. testing)
              "Yes",      # Factor level for "True"
              0.1)        # New cutoff value
    ```

* ROC Curve for Holdout Sample
    * Area between $.5$ and $.7$ suggests poor model fit

    ```{r t4roctest1, echo=FALSE, cache=TRUE, message=FALSE, fig.cap="ROC Curve for Test/Holdout Sample ([R code](#figure-reffigt4roctest1))"}
    # Use the 'logreg_roc.R' user-defined script
    source("Topic03/logreg_roc.R")
    # Requires package 'pROC' and 'ggplot2
    library(pROC)
    logreg_roc(tgt.log,   # Object with model results
               test)      # Data to use (i.e., training vs. testing)
    ```    

### Interpreting Coefficients

* `age` is positive ($OR>1$) and significant ($p=.0017$)
    * $1$ year increase in age increases odds of buying by a factor of $1.021$ (or odds of buying increase by $2.1\%$)
* `married` is negative ($OR<1$) and significant ($p<.0001$)
    * Being married decreases odds of buying by factor of $.56$ (or odds of buying decrease by $44\%$)
* `housing` is negative ($OR<1$) and significant ($p<.0001$)
    * Having a home loan decreases odds of buying by factor of $.56$ (or odds of buying decrease by $44\%$)
* `loan` is negative ($OR<1$) and significant ($p=.0025$)
    * Having a personal loan decreases odds of buying by factor of $.50$ (or odds of buying decrease by $50\%$)

### Interpreting Coefficients Visually

```{r t4lrmarginplots, echo=FALSE, message=FALSE, fig.cap="Margin Plots for Significant IVs ([R code](#figure-reffigt4lrmarginplots))"}
    age.p <- data.frame(predictorEffect("age", tgt.log))
    p6 <- age.p %>%
      ggplot(aes(x=age, y=fit)) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
        labs(x="Age", y="Pr(Response)") +
        scale_y_continuous(limits=c(0,.3))
    
    mar.p <- data.frame(predictorEffect("married", tgt.log))
    p7 <- mar.p %>%
      ggplot(aes(x=married, y=fit, group=1)) +
        geom_point(size=4) + 
        geom_line(color="orange") + 
        geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
        labs(x="Married") +
        theme(axis.title.y=element_blank()) +
        scale_y_continuous(limits=c(0,.3))
    
    ln.p <- data.frame(predictorEffect("loan", tgt.log))
    p8 <- ln.p %>%
      ggplot(aes(x=loan, y=fit, group=1)) +
        geom_point(size=4) + 
        geom_line(color="orange") + 
        geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
        labs(x="Personal Loan", y="Pr(Response)") +
        scale_y_continuous(limits=c(0,.3))
    
    hl.p <- data.frame(predictorEffect("housing", tgt.log))
    p9 <- hl.p %>%
      ggplot(aes(x=housing, y=fit, group=1)) +
        geom_point(size=4) + 
        geom_line(color="orange") + 
        geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
        labs(x="Housing Loan") +
        theme(axis.title.y=element_blank()) +
        scale_y_continuous(limits=c(0,.3))
    
    plot_grid(p6, p7, p8, p9, nrow=2)
```

### Gain Chart

* Contacting top $20\%$ of predicted buyers yields about $40\%$ of actual buyers
* Contacting top $30\%$ of predicted buyers yields about $52\%$ of actual buyers

    ```{r t4gainlift01, echo=FALSE, fig.cap="Gain Chart ([R code](#figure-reffigt4gainlift01))"}
    # Load user-defined object 'gainlift'
    source("Topic03/gainlift.R")

    # Call the function and assign to object named 'glresults'
    glresults <- gainlift(tgt.log,  # Name of the glm results object
                          train,  # Name of the training data frame
                          test,   # Name of the testing data frame
                          "Yes")  # Level that represents success/true
    
    # Output gainplot
    glresults$gainplot
    ```

### Lift Chart

* Contacting top $20\%$ of predicted buyers provides a lift of about $2$ 
    ```{r t4gainlift02, echo=FALSE, fig.cap="Lift Chart ([R code](#figure-reffigt4gainlift02))"}
    # Output liftplot
    glresults$liftplot
    ```

### Conclusion

Recall our goal:

* Predict current customers likely to buy

What did we learn?

* We can identify those more likely to buy by examining `age`, `married`, `housing`, and `loan`
* By targeting those customers that are more likely to purchase, we can better spend our limited resources

## Suggested Readings

* *Marketing Data Science* (2015). Miller, Thomas W.
     * BGSU Library Link:<br><a href="http://maurice.bgsu.edu:2083/record=b41416968~S0" target="_blank" rel="noopener noreferrer">http://maurice.bgsu.edu:2083/record=b41416968~S0</a>
    * eBook through BGSU Library:<br><a href="https://learning.oreilly.com/library/view/marketing-data-science/9780133887662/?ar=" target="_blank" rel="noopener noreferrer">https://learning.oreilly.com/library/view/marketing-data-science/9780133887662/?ar=</a><br>Note: Might need to create an account; select "Not Listed. Click here" from the "Select your institution" drop down box. Use your BGSU email to create the account.
    * Chapter 3: Targeting Current Customers



## R Code

### Figure \@ref(fig:t4scatmat01) {.unlisted .unnumbered}

```{r t4scatmat01code, eval=FALSE}
# Need to detach package 'cowplot' to prevent an error
detach("package:cowplot", unload = TRUE)  
ggpairs(telecom[,1:6], # Dataset
        lower=list(continuous=
                       wrap("smooth", 
                            method="lm", 
                            se=FALSE, # Add fit line
                       color="midnightblue")),  # Set dot color
    diag=list(continuous="blankDiag"))  # Set diagonals to be blank
# Reload 'cowplot'
library(cowplot)
```   

### Figure \@ref(fig:t4marginplots01) {.unlisted .unnumbered}

```{r t4marginplots01code, eval=FALSE}
# Use package 'effects'
library(effects)
    
# Create data frame of values to be plotted for 'avg6mou' as focal
a6.p <- data.frame(predictorEffect("avg6mou", target, 
                                   focal.levels=seq(0,1500,30)))
    
# Create plot and assign to p1
p1 <- a6.p %>%
  ggplot(aes(x=avg6mou, y=fit)) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
    labs(x="Mean Monthly Minutes", y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))

# Repeat for other Significant IVs
cc.p <- data.frame(predictorEffect("cc", target,
                                   focal.levels=seq(0,10,.2)))
p2 <- cc.p %>%
  ggplot(aes(x=cc, y=fit)) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
    labs(x="Mean Monthly Customer Care Calls", y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
  
da.p <- data.frame(predictorEffect("da", target,
                                   focal.levels=seq(0,10,.2)))
p3 <- da.p %>%
  ggplot(aes(x=da, y=fit)) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
    labs(x="Mean Monthly Directory Assistance Calls", y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))

#Arrange in grid using 'cowplot'
plot_grid(p1, p2, p3, nrow=2)
```

### Figure \@ref(fig:t4marginplots01b) {.unlisted .unnumbered}

```{r t4marginplots01bcode, eval=FALSE}
om.p <- data.frame(predictorEffect("ovrmou", target,
                                   focal.levels=seq(0,300,6)))
p4 <- om.p %>%
  ggplot(aes(x=ovrmou, y=fit, color=own, fill=own)) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
    labs(x="Mean Monthly Overage Minutes", y="Linear Prediction",
         color="Homeowner", fill="Homeowner") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15)) +
    theme(legend.position = "bottom")
    
own.p <- data.frame(predictorEffect("own", target,
                                    xlevels=list(ovrmou=seq(0,300,100))))
p5 <- own.p %>%
  ggplot(aes(x=own, y=fit, group=1)) +
    geom_point(size=2) +
    geom_line(color="orange") +
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
    facet_wrap(~ovrmou) +
    labs(x="Home Ownership", y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
    
plot_grid(p4, p5, nrow=1)
```

### Figure \@ref(fig:t4marginplots02) {.unlisted .unnumbered}

```{r t4marginplots02code, eval=FALSE}
# Create data frame of values to be plotted for 'avg6mou' as focal
inc.p <- data.frame(predictorEffect("income", target))
    
# Create plot
inc.p %>%
  ggplot(aes(x=income, y=fit)) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
    labs(x="Income (000s)", y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15))
```       

### Figure \@ref(fig:t4lrmarginplots) {.unlisted .unnumbered}

```{r t4lrmarginplotscode, eval=FALSE}
age.p <- data.frame(predictorEffect("age", tgt.log))
p6 <- age.p %>%
  ggplot(aes(x=age, y=fit)) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) +
    labs(x="Age", y="Pr(Response)") +
    scale_y_continuous(limits=c(0,.3))
    
mar.p <- data.frame(predictorEffect("married", tgt.log))
p7 <- mar.p %>%
  ggplot(aes(x=married, y=fit, group=1)) +
    geom_point(size=4) + 
    geom_line(color="orange") + 
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
    labs(x="Married") +
    theme(axis.title.y=element_blank()) +
    scale_y_continuous(limits=c(0,.3))
    
ln.p <- data.frame(predictorEffect("loan", tgt.log))
p8 <- ln.p %>%
  ggplot(aes(x=loan, y=fit, group=1)) +
    geom_point(size=4) + 
    geom_line(color="orange") + 
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
    labs(x="Personal Loan", y="Pr(Response)") +
    scale_y_continuous(limits=c(0,.3))

hl.p <- data.frame(predictorEffect("housing", tgt.log))
p9 <- hl.p %>%
  ggplot(aes(x=housing, y=fit, group=1)) +
    geom_point(size=4) + 
    geom_line(color="orange") + 
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) +
    labs(x="Housing Loan") +
    theme(axis.title.y=element_blank()) +
    scale_y_continuous(limits=c(0,.3))
    
plot_grid(p6, p7, p8, p9, nrow=2)
```

### Figure \@ref(fig:t4gainlift01) {.unlisted .unnumbered}

```{r t4gainlift01code, eval=FALSE}
# Load user-defined object 'gainlift'
source("Topic03/gainlift.R")
# Call the function and assign to object named 'glresults'
glresults <- gainlift(tgt.log,  # Name of the glm results object
                      train,  # Name of the training data frame
                      test,   # Name of the testing data frame
                      "Yes")  # Level that represents success/true
    
# Output gainplot
glresults$gainplot
```

### Figure \@ref(fig:t4gainlift02) {.unlisted .unnumbered}

```{r t4gainlift02code, eval=FALSE}
# Output liftplot
glresults$liftplot
```

### Table \@ref(tab:t4summstat01) {.unlisted .unnumbered}

``` {r t4summstat01code, eval=FALSE}
summary(telecom)
```

### Table \@ref(tab:t4lr01) {.unlisted .unnumbered}

```{r t4lr01code, eval=FALSE}
target <- lm(avg6rev ~ avg6mou + cc + da + ovrmou + income + own,
             data=telecom)
summary(target)

```

### Table \@ref(tab:t4tgtdecile) {.unlisted .unnumbered}

```{r t4tgtdecilecode, eval=FALSE}
telecom %>%
    cbind(., yhat=fitted(target)) %>%  # Append fitted values to data
    mutate(yhat.dec=11-ntile(yhat, 10),  # Create deciles, but reverse order
           own=as.numeric(own)-1) %>%  # Covert own to 1=yes, 0=no
    group_by(yhat.dec) %>%  # Group by decile
    summarise(across(avg6rev:own, 
                ~mean(.x, na.rm=TRUE))) %>%  # Calculate mean of each IV
    flextable()  # Nice table
```

### Table \@ref(tab:t4lrestimation) {.unlisted .unnumbered}

``` {r t4lrestimationcode, eval=FALSE }
# Use 'caret' package to create training and test/holdout samples
library(caret)
# This will create two separate dataframes: train and test
set.seed(9999)
inTrain <- createDataPartition(y=bankmktg$response, p=.75, list=FALSE)
train <- bankmktg[inTrain,]
test <- bankmktg[-inTrain,]

# Estimate using training sample
tgt.log <- glm(response ~ age + balance + default + housing + educ + 
                          loan + married, data=train, family="binomial")
summary(tgt.log)

# Get p-value
p <- with(tgt.log, pchisq(null.deviance - deviance,
                   df.null-df.residual,
                   lower.tail=FALSE))
cat("Model p-value =",sprintf("%.4f",p),"\ ")

# Calculate McFadden's R-sq
Mrsq <- 1-tgt.log$deviance/tgt.log$null.deviance
cat("McFadden's Pseudo-Rsquared = ", round(Mrsq, digits=4))

# Use the 'or_table.R' user-defined script to get Odds Ratio estimates
source("Topic03/or_table.R")
flextable(or_table(tgt.log))
```
