```{r echo=FALSE}
knitr::opts_chunk$set(comment=NA)
options(scipen=5)  # Turns off scientific notation
```

# Targeting and Retaining Customers

## R Packages and Datasets for Topic 4

``` {r t4packagesdata, message=FALSE}
library(cowplot)       # Arrange plots in grid
library(ggplot2)       # Advanced graphing capabilities
library(tidyr)         # Easier programming 
library(GGally)        # Scatterplot matrix
library(flextable)     # Better HTML Tables
library(htmlTable)     # Better HTML Tables
library(jtools)        # Concise regression results
library(dplyr)         # Easier programming
library(caret)         # Create data partitions
load("Topic04/bankmktg.rdata")
load("Topic04/telecom.rdata")
```

## Targeting Customers

* One-to-One Marketing
    * Time consuming
    * Costly
* Mass Marketing
    * Customer needs not being met
* Target Marketing
    * Market to those likely to...

### Goal

Target customers with the highest likelihood of a favorable outcome using explanatory variables

* Outcome variable could be:
    * Purchase
    * Sales
    * Costs
    * Profitability
    * CLV
* Explanatory variables could be:
    * Demographics
    * Behaviors
    * Usage
    * Lifestyles
    
The outcome variable will dictate the type of analysis we can perform

* Continuous outcome variables have a meaningful magnitude
    * Use linear regression
* Categorical outcome variables do not have a meaningful magnitude
    * Use logistic regression
    
## Retaining Customers

Importance of retention:

> Reducing defections $5\%$ boosts profits $25\%$ to $85\%$.  â€” Frederick F. Reichheld and W. Earl Sasser, Jr.

### Goal

Identify factors (i.e., independent variables) that increase the likelihood of retention (or decrease the likelihood of churn)

* Retention (or Churn) is the outcome or dependent variable
    * DV = Binary, so Method = Logistic Regression
    
## Targeting Customers (Linear Regression) Example

### Overview

* Customer revenue, usage, and demographics for a cell phone provider
* DV:
    * Mean monthly revenue (prior 6 months), `avg6rev`
* IVs:
    * Mean monthly minutes (prior 6 months), `avg6mou`
    * Mean monthly customer care calls, `cc`
    * Mean monthly directory assistance calls, `da`
    * Mean monthly overage minutes, `ovrmou`
    * Household income (dollars), `income`
    * Own home (Yes; No), `own`
    
### Summarize Data

* Useful to examine data prior to specifying the model
    * Summary Statistics  
    <caption>(\#tab:t4summstat01) Summary Statistics ([R code](#table-reftabt4summstat01))</caption>
    ``` {r t4summstat01, echo=FALSE, message=FALSE}
    library(vtable)
    sumtable(telecom, out="return") %>% kable(caption=NULL)
    ```

    * Scatterplot Matrix (with Correlations)
    ```{r t4scatmat01, echo=FALSE, fig.cap="Scatterplot Matrix with Correlations ([R code](#figure-reffigt4scatmat01))", message=FALSE}
    # Need to detach package 'cowplot' to prevent an error
    detach("package:cowplot", unload = TRUE)  
    ggpairs(telecom[,1:6], # Dataset
            lower=list(continuous=
                           wrap("smooth", 
                                method="lm", 
                                se=FALSE, # Add fit line
                           color="midnightblue")),  # Set dot color
        diag=list(continuous="blankDiag"))  # Set diagonals to be blank
    # Reload 'cowplot'
    library(cowplot)
    ```

### Model Specification

* Goal: Determine what behaviors and demographics are associated with high revenue customers
* IVs are expected to be ones that are related to revenue
* Model: $avg6rev=\alpha+\beta_1avg6mou+\beta_2cc+\beta_3da+\beta_4ovrmou+\beta_5income+\beta_6own$

### Model Interpretation

#### Results

<caption>(\#tab:t4lr01) Linear Regression Results ([R code](#table-reftabt4lr01))</caption>
```{r t4lr01, echo=FALSE}
target <- lm(avg6rev ~ avg6mou + cc + da + ovrmou + income + own,
             data=telecom)
summary(target)

```
$avg6rev=31.421+.049avg6mou-1.263cc+1.925da+.178ovrmou-.013income-4.086own$

#### Testing Overall Model Significance

* Relationship between DV and combined effects of IVs
* $H_0: \text{all }\beta_k=0$ vs. $H_a: \text{at least one }\beta_k\ne0$
* Use F-statistic to test
* Conclusion:  With a F-statistic of $923.2$ and a $p<.001$, we conclude that at least one $\beta_k$ is significant

#### Assessing overall model fit

* How much variation in the DV is explained by the model
* Use $R^2$ to assess
* Use Adjusted $R^2$ to compare models
* Conclusion: Based on the $R^2$, about $70\%$ of the variance in `avg6rev` is explained by the model

#### Interpret Individual IVs

* Relationship between DV and each IV
* $H_0: \beta_k=0$ vs. $H_a: \beta_k\ne0$
* Interpret significant relationships
    * `avg6mou`
        * With $p<.001$, `avg6mou` has a significant effect on `avg6rev`.
        * A one unit increase in `avg6mou` is predicted to increase `avg6rev` by $.049$ units.
    * `cc`
        * With $p<.001$, `cc` has a significant effect on `avg6rev`.
        * A one unit increase in `cc` is predicted to decrease `avg6rev` by $1.263$ units.
    * `da`
        * With $p<.001$, `da` has a significant effect on `avg6rev`.
        * A one unit increase in `da` is predicted to increase `avg6rev` by $1.925$ units.
    * `ovrmou`
        * With $p<.001$, `ovrmou` has a significant effect on `avg6rev`.
        * A one unit increase in `ovrmou` is predicted to increase `avg6rev` by $.178$ units.
    * `own`
        * With $p<.001$, `own` has a significant effect on `avg6rev`.
        * Those that own their home have $4.086$ units less revenue per month than those that do not.
* A standardized $\beta$ is the effect of a single standard deviation change in the IV on the DV
    * Higher absolute values are more important
    * Conclusion: `avg6mou` is the biggest driver of avg6rev

    <caption>(\#tab:t4stdbeta1) Standardized Beta Coefficients ([R code](#table-reftabt4stdbeta1))</caption>
    ```{r t4lrstdbeta1, echo=FALSE}
    # Use user-defined function 'lm_beta.R'
    source("Topic02/lm_beta.R")
    htmlTable(lm_beta(target, digits=4))
    ```

* Sometimes helps to visually examine the IVs for interpretation
* Plots can show predicted DV at different levels of IVs 

    ```{r t4marginplots01, echo=FALSE, fig.cap="Margin Plots for Significant IVs ([R code](#figure-reffigt4marginplots01))"}
    # Want to predict for different levels of IVs
    # Because we often do this for other continuous variables, we first
    #     create a df with mean values of all continuous IVs
    #     at different levels of the factor variable (if there are any)
    # NOTE: variable names must be EXACTLY the same as in model
    m.ivs <- telecom %>%
      group_by(own) %>%
      summarise(avg6mou=mean(avg6mou, na.rm=TRUE),
                cc=mean(cc, na.rm=TRUE),
                da=mean(da, na.rm=TRUE),
                ovrmou=mean(ovrmou, na.rm=TRUE),
                income=mean(income, na.rm=TRUE))
    
    # Create dataframe for prediction at different levels of 'avg6mou'
    a6m.pred <- merge(data.frame(avg6mou=seq(0,1500,100)), # variable of interest
                         m.ivs[,c("cc", "da", "ovrmou", "income", "own")])
    
    # Use model results to predict dv for values in 'a6m.pred' data frame
    # Predicted values and CIs get appended to data frame
    # New variables are called:
    #      'p$fit' = linear prediction from model
    #      'p$lwr' = lower confidence interval for prediction
    #      'p$upr' = upper confidcent interval for prediction
    a6m.pred$p <- as.data.frame(
       predict.lm(target,    
                  a6m.pred,
                  interval="confidence"))
    # Use ggplot to create margin plot
    p1 <- ggplot(aes(x=avg6mou, y=p$fit, color=own), data=a6m.pred) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
        labs(x="Mean Monthly Minutes", y="Linear Prediction", 
             fill="Own", color="Own") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                           minor_breaks=NULL) +
        theme(legend.position="none")
    
    # Repeat for variable 'cc'
    cc.pred <- merge(data.frame(cc=seq(0,10,1)), # variable of interest
                         m.ivs[,c("avg6mou", "da", "ovrmou", "income", "own")])
    cc.pred$p <- as.data.frame(predict.lm(target, cc.pred,
                                          interval="confidence"))
    p2 <- ggplot(aes(x=cc, y=p$fit, color=own), data=cc.pred) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
        labs(x="Mean Monthly Customer Care Calls", y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                           minor_breaks=NULL) +
        theme(legend.position="none")
 
    
    # Repeat for variable 'da'
    da.pred <- merge(data.frame(da=seq(0,10,1)), # variable of interest
                         m.ivs[,c("cc", "avg6mou", "ovrmou", "income", "own")])
    da.pred$p <- as.data.frame(predict.lm(target, da.pred,
                                          interval="confidence"))
    p3 <- ggplot(aes(x=da, y=p$fit, color=own), data=da.pred) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
        labs(x="Mean Monthly Directory Assistance Calls", 
             y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                           minor_breaks=NULL) +
        theme(legend.position="none")
    
    # Repeat for variable 'ovrmou'
    om.pred <- merge(data.frame(ovrmou=seq(0,300,25)), # variable of interest
                         m.ivs[,c("cc", "da", "avg6mou", "income", "own")])
    om.pred$p <- as.data.frame(predict.lm(target, om.pred,
                                          interval="confidence"))
    p4 <- ggplot(aes(x=ovrmou, y=p$fit, color=own), data=om.pred) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
        labs(x="Mean Monthly Overage Minutes", 
             y="Linear Prediction") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                           minor_breaks=NULL) +
        theme(legend.position="none")
    pgrid <- plot_grid(p1, p2, p3, p4, nrow=2)
    legend <- get_legend(p1 + theme(legend.position="bottom"))
    plot_grid(pgrid, legend, ncol=1, rel_heights=c(1,.1))
    ```

    ```{r t4marginplots02, echo=FALSE, fig.cap="Margin Plots for Insignificant IV ([R code](#figure-reffigt4marginplots02))"}
    # Create dataframe for prediction at different levels of 'avg6mou'
    inc.pred <- merge(data.frame(income=seq(10,200,10)), # variable of interest
                         m.ivs[,c("cc", "da", "ovrmou", "avg6mou", "own")])
    
    # Use model results to predict dv for values in 'a6m.pred' data frame
    # Predicted values and CIs get appended to data frame
    # New variables are called:
    #      'p$fit' = linear prediction from model
    #      'p$lwr' = lower confidence interval for prediction
    #      'p$upr' = upper confidcent interval for prediction
    inc.pred$p <- as.data.frame(
       predict.lm(target,    
                  inc.pred,
                  interval="confidence"))
    # Use ggplot to create margin plot
    ggplot(aes(x=income, y=p$fit, color=own), data=inc.pred) +
        geom_line(size=1) +
        geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
        labs(x="Income (000s)", y="Linear Prediction", 
             fill="Own", color="Own") +
        scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                           minor_breaks=NULL) +
        theme(legend.position="bottom")
    ```       
* Examine deciles of predicted values by the IVs
    * Split sample into 10 groups based on predicted DV
    * Look at mean values of IVs for each decile  
    
    
    <caption>(\#tab:t4tgtdecile) IVs by Predicted Deciles ([R code](#table-reftabt4tgtdecile))</caption>
    ```{r t4tgtdecile, echo=FALSE}
    telecom %>%
        cbind(., yhat=fitted(target)) %>%  # Append fitted values to data
        mutate(yhat.dec=11-ntile(yhat, 10),  # Create deciles, but reverse order
               own=as.numeric(own)-1) %>%  # Covert own to 1=yes, 0=no
        group_by(yhat.dec) %>%  # Group by decile
        summarise(across(avg6rev:own, 
                    ~mean(.x, na.rm=TRUE))) %>%  # Calculate mean of each IV
        flextable()  # Nice table
    ```

### Conclusion

Recall our Goal:<br>
Determine what behaviors and demographics are associated with high revenue customers

What did we learn?

* We can identify our highest revenue customers by examining `avg6mou`, `cc`, `da`, `ovrmou` and `own`
* Our highest revenue customers consumer over $1000$ minutes per month and have over $200$ overage minutes per month
* More directory assistance calls and fewer customer care calls are associated with higher revenue


## Targeting Customers (Logistic Regression)

### Overview

* Bank marketing data for customers of a bank
* DV:
    * Open term deposit account, `response`
* IVs:
    * Age, `age`
    * Average Yearly Balance, `balance`
    * Housing Loan (Yes, No), `housing`
    * Personal Loan (Yes, No), `loan`
    * Married (Yes, No), `married`
* Predict current customers likely to buy
    * Use training (75%) and holdout (25%) samples

### Estimation Results
    
<caption>(\#tab:t4lrestimation) Logistic Regression Estimation Results on Training Sample ([R code](#table-reftabt4lrestimation))</caption>
``` {r t4lrestimation, echo=FALSE }
# Use 'caret' package to create training and test/holdout samples
library(caret)
# This will create two separate dataframes: train and test
set.seed(9999)
inTrain <- createDataPartition(y=bankmktg$response, p=.75, list=FALSE)
train <- bankmktg[inTrain,]
test <- bankmktg[-inTrain,]

# Estimate using training sample
tgt.log <- glm(response ~ age + balance + housing + loan + married, 
               data=train, family="binomial")
summary(tgt.log)

# Get p-value
p <- with(tgt.log, pchisq(null.deviance - deviance,
                   df.null-df.residual,
                   lower.tail=FALSE))
cat("Model p-value =",sprintf("%.4f",p),"\ ")

# Calculate McFadden's R-sq
Mrsq <- 1-tgt.log$deviance/tgt.log$null.deviance
cat("McFadden's Pseudo-Rsquared = ", round(Mrsq, digits=4))

# Use the 'or_table.R' user-defined script to get Odds Ratio estimates
source("Topic03/or_table.R")
flextable(or_table(tgt.log))
```

### Overall Model Fit

* Based on the likelihood ratio test with p-value < .0001, the overall model is significant
* McFadden's Pseudo-$R^2$ of .030 means that the model explains only about 3% of variation between buyers/non-buyers
* Classification Matrix for Training Sample
* What's the problem?

    <caption>(\#tab:t4cmtrain1) Classification Matrix for Training Sample ([R code](#table-reftabt4cmtrain1))</caption>
    ```{r t4cmtrain1, echo=FALSE, cache=TRUE}
    # Use the 'logreg_cm.R' user-defined script
    source("Topic03/logreg_cm.R")
    # Requires package 'caret', loaded above
    logreg_cm(tgt.log,    # Object with model results
              train,      # Data to use (i.e., training vs. testing)
              "Yes")      # Factor level for "True"
    ```

* Sensitivity/Specificity Plot

    ```{r t4sensspec01, echo=FALSE, fig.cap="Sensitivity/Specificity Plot for Training Sample ([R code](#figure-reffigt4sensspec01))"}
    # Use the 'logreg_cut.R' user-defined script
    source("Topic03/logreg_cut.R")
    logreg_cut(tgt.log, train, "Yes")
    ```

* Classificaiton Matrix for Holdout Sample

    <caption>(\#tab:t4cmtrain2) Classification Matrix for Training Sample with 0.1 Cutoff ([R code](#table-reftabt4cmtrain2))</caption>
    ```{r t4cmtrain2, echo=FALSE, cache=TRUE}
    logreg_cm(tgt.log,    # Object with model results
              train,      # Data to use (i.e., training vs. testing)
              "Yes",      # Factor level for "True"
              0.1)        # New cutoff value
    ```

* Classification Matrix for Holdout Sample
    * Results very similar for holdout sample

    <caption>(\#tab:t4cmtrain3) Classification Matrix for Holdout Sample with 0.1 Cutoff ([R code](#table-reftabt4cmtrain3))</caption>
    ```{r t4cmtrain3, echo=FALSE, cache=TRUE}
    logreg_cm(tgt.log,    # Object with model results
              test,      # Data to use (i.e., training vs. testing)
              "Yes",      # Factor level for "True"
              0.1)        # New cutoff value
    ```

* ROC Curve for Holdout Sample
    * Area between $.5$ and $.7$ suggests poor model fit

    ```{r t4roctest1, echo=FALSE, cache=TRUE, message=FALSE, fig.cap="ROC Curve for Test/Holdout Sample ([R code](#figure-reffigt4roctest1))"}
    # Use the 'logreg_roc.R' user-defined script
    source("Topic03/logreg_roc.R")
    # Requires package 'pROC' and 'ggplot2
    library(pROC)
    logreg_roc(tgt.log,   # Object with model results
               test)      # Data to use (i.e., training vs. testing)
    ```    

### Interpreting Coefficients

* `age` is positive ($OR>1$) and significant ($p=.0017$)
    * $1$ year increase in age increases odds of buying by a factor of $1.021$ (or odds of buying increase by $2.1\%$)
* `married` is negative ($OR<1$) and significant ($p<.0001$)
    * Being married decreases odds of buying by factor of $.56$ (or odds of buying decrease by $44\%$)
* `housing` is negative ($OR<1$) and significant ($p<.0001$)
    * Having a home loan decreases odds of buying by factor of $.56$ (or odds of buying decrease by $44\%$)
* `loan` is negative ($OR<1$) and significant ($p=.0025$)
    * Having a personal loan decreases odds of buying by factor of $.50$ (or odds of buying decrease by $50\%$)

### Interpreting Coefficients Visually

```{r t4lrmarginplots, echo=FALSE, message=FALSE, fig.cap="Margin Plots for Age at Different Factor Levels ([R code](#figure-reffigt4lrmarginplots))"}
# Create df will mean values of continuous IVs at levels of factor IVs
m.ivs <- train %>%
   group_by(housing, loan, married) %>%
   summarise(age=mean(age, na.rm=TRUE),
             balance=mean(balance, na.rm=TRUE))

# Create new data for prediction with 'age' as focus
age.pred <- merge(data.frame(age=seq(15,85,5)), 
                  m.ivs[ ,c("housing", "loan", "married", "balance")])

# Create data frame with predicted values and confidence bands
train.pred <- 
cbind(age.pred,   # 'cbind' combines objects by columns 
      predict(tgt.log, # Model to predict values with
              age.pred, # New data to use for IVs
              type="link", # Return log-odds predictions
              se=TRUE)) %>%  # Get std.err. for CIs
    mutate(pred=plogis(fit), # Calculate pr(response)
           upr=plogis(fit+(qnorm(0.975)*se.fit)),  # Upper CI
           lwr=plogis(fit-(qnorm(0.975)*se.fit)))  # Lower CI

# Create plot grid with separate lines for 'housing'
ggplot(aes(x=age, y=pred), data=train.pred) +
   geom_line(aes(color=housing), size=1) +
   geom_ribbon(aes(ymin=lwr, ymax=upr, 
                   color=housing, fill=housing), alpha=.2) +
   scale_y_continuous("Pr(Response)",limits=c(0,.5)) +
   theme(legend.position="bottom") +
   # 'facet-grid' creates separate plots in a grid of factor variable levels
   facet_grid(rows=vars(married), cols=vars(loan),
              labeller=labeller(married=as_labeller(c("No"="Married: No", 
                                                      "Yes"="Married: Yes")),
                                loan=as_labeller(c("No"="Personal Loan: No", 
                                                   "Yes"="Personal Loan: Yes"))),
              switch="y") +
   labs(x="Age", color="Housing Loan", fill="Housing Loan")
```

### Gain Chart

* Contacting top $20\%$ of predicted buyers yields about $40\%$ of actual buyers
* Contacting top $30\%$ of predicted buyers yields about $52\%$ of actual buyers

    ```{r t4gainlift01, echo=FALSE, fig.cap="Gain Chart ([R code](#figure-reffigt4gainlift01))"}
    # Load user-defined object 'gainlift'
    source("Topic03/gainlift.R")

    # Call the function and assign to object named 'glresults'
    glresults <- gainlift(tgt.log,  # Name of the glm results object
                          train,  # Name of the training data frame
                          test,   # Name of the testing data frame
                          "Yes")  # Level that represents success/true
    
    # Output gainplot
    glresults$gainplot
    ```

### Lift Chart

* Contacting top $20\%$ of predicted buyers provides a lift of about $2$ 
    ```{r t4gainlift02, echo=FALSE, fig.cap="Lift Chart ([R code](#figure-reffigt4gainlift02))"}
    # Output liftplot
    glresults$liftplot
    ```

### Conclusion

Recall our goal:

* Predict current customers likely to buy

What did we learn?

* We can identify those more likely to buy by examining `age`, `married`, `housing`, and `loan`
* By targeting those customers that are more likely to purchase, we can better spend our limited resources

## Suggested Readings

* *Marketing Data Science* (2015). Miller, Thomas W.
     * BGSU Library Link:<br><a href="http://maurice.bgsu.edu:2083/record=b41416968~S0" target="_blank" rel="noopener noreferrer">http://maurice.bgsu.edu:2083/record=b41416968~S0</a>
    * eBook through BGSU Library:<br><a href="https://learning.oreilly.com/library/view/marketing-data-science/9780133887662/?ar=" target="_blank" rel="noopener noreferrer">https://learning.oreilly.com/library/view/marketing-data-science/9780133887662/?ar=</a><br>Note: Might need to create an account; select "Not Listed. Click here" from the "Select your institution" drop down box. Use your BGSU email to create the account.
    * Chapter 3: Targeting Current Customers



## R Code

### Figure \@ref(fig:t4scatmat01) {.unlisted .unnumbered}

```{r t4scatmat01code, eval=FALSE}
# Need to detach package 'cowplot' to prevent an error
detach("package:cowplot", unload = TRUE)  
ggpairs(telecom[,1:6], # Dataset
        lower=list(continuous=
                       wrap("smooth", 
                            method="lm", 
                            se=FALSE, # Add fit line
                       color="midnightblue")),  # Set dot color
    diag=list(continuous="blankDiag"))  # Set diagonals to be blank
# Reload 'cowplot'
library(cowplot)
```   

### Figure \@ref(fig:t4marginplots01) {.unlisted .unnumbered}

```{r t4marginplots01code, eval=FALSE}
# Want to predict for different levels of IVs
# Because we often do this for other continuous variables, we first
#     create a df with mean values of all continuous IVs
#     at different levels of the factor variable (if there are any)
# NOTE: variable names must be EXACTLY the same as in model
m.ivs <- telecom %>%
  group_by(own) %>%
  summarise(avg6mou=mean(avg6mou, na.rm=TRUE),
            cc=mean(cc, na.rm=TRUE),
            da=mean(da, na.rm=TRUE),
            ovrmou=mean(ovrmou, na.rm=TRUE),
            income=mean(income, na.rm=TRUE))

# Create dataframe for prediction at different levels of 'avg6mou'
a6m.pred <- merge(data.frame(avg6mou=seq(0,1500,100)), # variable of interest
                     m.ivs[,c("cc", "da", "ovrmou", "income", "own")])

# Use model results to predict dv for values in 'a6m.pred' data frame
# Predicted values and CIs get appended to data frame
# New variables are called:
#      'p$fit' = linear prediction from model
#      'p$lwr' = lower confidence interval for prediction
#      'p$upr' = upper confidcent interval for prediction
a6m.pred$p <- as.data.frame(
   predict.lm(target,    
              a6m.pred,
              interval="confidence"))
# Use ggplot to create margin plot
p1 <- ggplot(aes(x=avg6mou, y=p$fit, color=own), data=a6m.pred) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
    labs(x="Mean Monthly Minutes", y="Linear Prediction", 
         fill="Own", color="Own") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                       minor_breaks=NULL) +
    theme(legend.position="none")

# Repeat for variable 'cc'
cc.pred <- merge(data.frame(cc=seq(0,10,1)), # variable of interest
                     m.ivs[,c("avg6mou", "da", "ovrmou", "income", "own")])
cc.pred$p <- as.data.frame(predict.lm(target, cc.pred,
                                      interval="confidence"))
p2 <- ggplot(aes(x=cc, y=p$fit, color=own), data=cc.pred) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
    labs(x="Mean Monthly Customer Care Calls", y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                       minor_breaks=NULL) +
    theme(legend.position="none")


# Repeat for variable 'da'
da.pred <- merge(data.frame(da=seq(0,10,1)), # variable of interest
                     m.ivs[,c("cc", "avg6mou", "ovrmou", "income", "own")])
da.pred$p <- as.data.frame(predict.lm(target, da.pred,
                                      interval="confidence"))
p3 <- ggplot(aes(x=da, y=p$fit, color=own), data=da.pred) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
    labs(x="Mean Monthly Directory Assistance Calls", 
         y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                       minor_breaks=NULL) +
    theme(legend.position="none")

# Repeat for variable 'ovrmou'
om.pred <- merge(data.frame(ovrmou=seq(0,300,25)), # variable of interest
                     m.ivs[,c("cc", "da", "avg6mou", "income", "own")])
om.pred$p <- as.data.frame(predict.lm(target, om.pred,
                                      interval="confidence"))
p4 <- ggplot(aes(x=ovrmou, y=p$fit, color=own), data=om.pred) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
    labs(x="Mean Monthly Overage Minutes", 
         y="Linear Prediction") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                       minor_breaks=NULL) +
    theme(legend.position="none")
# Save Plots to a grid object using 'cowplot'
pgrid <- plot_grid(p1, p2, p3, p4, nrow=2)
# Extract legend from first plot
legend <- get_legend(p1 + theme(legend.position="bottom"))
# Combine plot object and legend in a single column
plot_grid(pgrid, legend, ncol=1, rel_heights=c(1,.1))
```

### Figure \@ref(fig:t4marginplots02) {.unlisted .unnumbered}

```{r t4marginplots02code, eval=FALSE}
# Create dataframe for prediction at different levels of 'avg6mou'
inc.pred <- merge(data.frame(income=seq(10,200,10)), # variable of interest
                     m.ivs[,c("cc", "da", "ovrmou", "avg6mou", "own")])

# Use model results to predict dv for values in 'a6m.pred' data frame
# Predicted values and CIs get appended to data frame
# New variables are called:
#      'p$fit' = linear prediction from model
#      'p$lwr' = lower confidence interval for prediction
#      'p$upr' = upper confidcent interval for prediction
inc.pred$p <- as.data.frame(
   predict.lm(target,    
              inc.pred,
              interval="confidence"))
# Use ggplot to create margin plot
ggplot(aes(x=income, y=p$fit, color=own), data=inc.pred) +
    geom_line(size=1) +
    geom_ribbon(aes(ymin=p$lwr, ymax=p$upr, fill=own), alpha=0.2) +
    labs(x="Income (000s)", y="Linear Prediction", 
         fill="Own", color="Own") +
    scale_y_continuous(limits=c(30,120), breaks=seq(30,120,15), 
                       minor_breaks=NULL) +
    theme(legend.position="bottom")
```       

### Figure \@ref(fig:t4lrmarginplots) {.unlisted .unnumbered}

```{r t4lrmarginplotscode, eval=FALSE}
# Create df will mean values of continuous IVs at levels of factor IVs
m.ivs <- train %>%
   group_by(housing, loan, married) %>%
   summarise(age=mean(age, na.rm=TRUE),
             balance=mean(balance, na.rm=TRUE))

# Create new data for prediction with 'age' as focus
age.pred <- merge(data.frame(age=seq(15,85,5)), 
                  m.ivs[ ,c("housing", "loan", "married", "balance")])

# Create data frame with predicted values and confidence bands
train.pred <- 
cbind(age.pred,   # 'cbind' combines objects by columns 
      predict(tgt.log, # Model to predict values with
              age.pred, # New data to use for IVs
              type="link", # Return log-odds predictions
              se=TRUE)) %>%  # Get std.err. for CIs
    mutate(pred=plogis(fit), # Calculate pr(response)
           upr=plogis(fit+(qnorm(0.975)*se.fit)),  # Upper CI
           lwr=plogis(fit-(qnorm(0.975)*se.fit)))  # Lower CI

# Create plot grid with separate lines for 'housing'
ggplot(aes(x=age, y=pred), data=train.pred) +
   geom_line(aes(color=housing), size=1) +
   geom_ribbon(aes(ymin=lwr, ymax=upr, 
                   color=housing, fill=housing), alpha=.2) +
   scale_y_continuous("Pr(Response)",limits=c(0,.5)) +
   theme(legend.position="bottom") +
   # 'facet-grid' creates separate plots in a grid of factor variable levels
   facet_grid(rows=vars(married), cols=vars(loan),
              labeller=labeller(married=as_labeller(c("No"="Married: No", 
                                                      "Yes"="Married: Yes")),
                                loan=as_labeller(c("No"="Personal Loan: No", 
                                                   "Yes"="Personal Loan: Yes"))),
              switch="y") +
   labs(x="Age", color="Housing Loan", fill="Housing Loan")
```

### Figure \@ref(fig:t4gainlift01) {.unlisted .unnumbered}

```{r t4gainlift01code, eval=FALSE}
# Load user-defined object 'gainlift'
source("Topic03/gainlift.R")
# Call the function and assign to object named 'glresults'
glresults <- gainlift(tgt.log,  # Name of the glm results object
                      train,  # Name of the training data frame
                      test,   # Name of the testing data frame
                      "Yes")  # Level that represents success/true
    
# Output gainplot
glresults$gainplot
```

### Figure \@ref(fig:t4gainlift02) {.unlisted .unnumbered}

```{r t4gainlift02code, eval=FALSE}
# Output liftplot
glresults$liftplot
```

### Table \@ref(tab:t4summstat01) {.unlisted .unnumbered}

``` {r t4summstat01code, eval=FALSE}
summary(telecom)
```

### Table \@ref(tab:t4lr01) {.unlisted .unnumbered}

```{r t4lr01code, eval=FALSE}
target <- lm(avg6rev ~ avg6mou + cc + da + ovrmou + income + own,
             data=telecom)
summary(target)

```

### Table \@ref(tab:t4stdbeta11) {.unlisted .unnumbered}

```{r t4lrstdbeta1code, eval=FALSE}
# Use user-defined function 'lm_beta.R'
source("Topic02/lm_beta.R")
htmlTable(lm_beta(target, digits=4))
```

### Table \@ref(tab:t4tgtdecile) {.unlisted .unnumbered}

```{r t4tgtdecilecode, eval=FALSE}
telecom %>%
    cbind(., yhat=fitted(target)) %>%  # Append fitted values to data
    mutate(yhat.dec=11-ntile(yhat, 10),  # Create deciles, but reverse order
           own=as.numeric(own)-1) %>%  # Covert own to 1=yes, 0=no
    group_by(yhat.dec) %>%  # Group by decile
    summarise(across(avg6rev:own, 
                ~mean(.x, na.rm=TRUE))) %>%  # Calculate mean of each IV
    flextable()  # Nice table
```

### Table \@ref(tab:t4lrestimation) {.unlisted .unnumbered}

``` {r t4lrestimationcode, eval=FALSE }
# Use 'caret' package to create training and test/holdout samples
library(caret)
# This will create two separate dataframes: train and test
set.seed(9999)
inTrain <- createDataPartition(y=bankmktg$response, p=.75, list=FALSE)
train <- bankmktg[inTrain,]
test <- bankmktg[-inTrain,]

# Estimate using training sample
tgt.log <- glm(response ~ age + balance + default + housing + educ + 
                          loan + married, data=train, family="binomial")
summary(tgt.log)

# Get p-value
p <- with(tgt.log, pchisq(null.deviance - deviance,
                   df.null-df.residual,
                   lower.tail=FALSE))
cat("Model p-value =",sprintf("%.4f",p),"\ ")

# Calculate McFadden's R-sq
Mrsq <- 1-tgt.log$deviance/tgt.log$null.deviance
cat("McFadden's Pseudo-Rsquared = ", round(Mrsq, digits=4))

# Use the 'or_table.R' user-defined script to get Odds Ratio estimates
source("Topic03/or_table.R")
flextable(or_table(tgt.log))
```
